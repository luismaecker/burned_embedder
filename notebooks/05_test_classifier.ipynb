{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ef0749c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from burned_embedder.utils import setup_device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2a99e4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scripts/analyze_experiments_extended.py\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import rootutils\n",
    "from scipy import stats\n",
    "\n",
    "root_path = rootutils.find_root()\n",
    "\n",
    "\n",
    "\n",
    "def results_to_dataframe(results):\n",
    "    \"\"\"Convert results list to pandas DataFrame with extended features\"\"\"\n",
    "    if not results:\n",
    "        raise ValueError(\"No results to analyze\")\n",
    "    \n",
    "    data = []\n",
    "    for result in results:\n",
    "        row = {\n",
    "            'experiment': result['experiment_name'],\n",
    "            'test_f1': result['test_f1'],\n",
    "            'test_precision': result['test_precision'],\n",
    "            'test_recall': result['test_recall'],\n",
    "            'test_roc_auc': result['test_roc_auc'],\n",
    "            'val_f1': result['best_val_f1'],\n",
    "            'overfit_gap': result['overfit_gap'],\n",
    "            'best_epoch': result['best_epoch'],\n",
    "            'input_type': result['config']['input_type'],\n",
    "            'hidden_dims': str(result['config']['hidden_dims']),\n",
    "            'dropout': result['config']['dropout'],\n",
    "            'lr': result['config']['lr'],\n",
    "            'weight_decay': result['config']['weight_decay'],\n",
    "            'batch_size': result['config']['batch_size'],\n",
    "            'patience': result['config'].get('patience', 15),\n",
    "            'seed': result['config']['seed'],\n",
    "        }\n",
    "        \n",
    "        # Compute derived metrics\n",
    "        cm = np.array(result['confusion_matrix'])\n",
    "        row['tn'] = cm[0, 0]\n",
    "        row['fp'] = cm[0, 1]\n",
    "        row['fn'] = cm[1, 0]\n",
    "        row['tp'] = cm[1, 1]\n",
    "        row['false_positive_rate'] = row['fp'] / (row['fp'] + row['tn']) if (row['fp'] + row['tn']) > 0 else 0\n",
    "        row['false_negative_rate'] = row['fn'] / (row['fn'] + row['tp']) if (row['fn'] + row['tp']) > 0 else 0\n",
    "        \n",
    "        # Model complexity\n",
    "        hidden_list = eval(result['config']['hidden_dims'])\n",
    "        row['num_layers'] = len(hidden_list)\n",
    "        row['total_hidden_units'] = sum(hidden_list)\n",
    "        row['max_layer_size'] = max(hidden_list)\n",
    "        \n",
    "        data.append(row)\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "\n",
    "def print_summary_table(df, top_n=20):\n",
    "    \"\"\"Print formatted summary table\"\"\"\n",
    "    print(\"\\n\" + \"=\"*120)\n",
    "    print(\"EXPERIMENT RESULTS SUMMARY\")\n",
    "    print(\"=\"*120)\n",
    "    \n",
    "    df_sorted = df.sort_values('test_f1', ascending=False)\n",
    "    \n",
    "    print(f\"\\n{'Rank':<6}{'Experiment':<35}{'F1':<8}{'Prec':<8}{'Recall':<8}{'AUC':<8}{'Overfit':<10}{'Epoch':<7}\")\n",
    "    print(\"-\"*120)\n",
    "    \n",
    "    for idx, (_, row) in enumerate(df_sorted.head(top_n).iterrows(), 1):\n",
    "        print(f\"{idx:<6}{row['experiment']:<35}{row['test_f1']:<8.4f}{row['test_precision']:<8.4f}\"\n",
    "              f\"{row['test_recall']:<8.4f}{row['test_roc_auc']:<8.4f}{row['overfit_gap']:<10.4f}{row['best_epoch']:<7.0f}\")\n",
    "    \n",
    "    # Print bottom performers too\n",
    "    print(\"\\n\" + \"-\"*120)\n",
    "    print(\"BOTTOM 5 PERFORMERS:\")\n",
    "    print(\"-\"*120)\n",
    "    for idx, (_, row) in enumerate(df_sorted.tail(5).iterrows(), len(df_sorted)-4):\n",
    "        print(f\"{idx:<6}{row['experiment']:<35}{row['test_f1']:<8.4f}{row['test_precision']:<8.4f}\"\n",
    "              f\"{row['test_recall']:<8.4f}{row['test_roc_auc']:<8.4f}{row['overfit_gap']:<10.4f}{row['best_epoch']:<7.0f}\")\n",
    "    \n",
    "    # Best by different metrics\n",
    "    print(f\"\\n\" + \"=\"*120)\n",
    "    print(\"BEST MODELS BY METRIC\")\n",
    "    print(\"=\"*120)\n",
    "    \n",
    "    metrics = {\n",
    "        'F1 Score': ('test_f1', 'max'),\n",
    "        'Precision': ('test_precision', 'max'),\n",
    "        'Recall': ('test_recall', 'max'),\n",
    "        'AUC': ('test_roc_auc', 'max'),\n",
    "        'Least Overfit': ('overfit_gap', 'min'),\n",
    "        'Fastest Convergence': ('best_epoch', 'min'),\n",
    "        'Best Val-Test Agreement': ('overfit_gap', 'abs_min'),\n",
    "    }\n",
    "    \n",
    "    for metric_name, (col, agg) in metrics.items():\n",
    "        if agg == 'abs_min':\n",
    "            idx = df[col].abs().idxmin()\n",
    "        else:\n",
    "            idx = df[col].idxmax() if agg == 'max' else df[col].idxmin()\n",
    "        row = df.loc[idx]\n",
    "        print(f\"\\n{metric_name}:\")\n",
    "        print(f\"  Model: {row['experiment']}\")\n",
    "        print(f\"  Value: {row[col]:.4f}\")\n",
    "        print(f\"  Config: input={row['input_type']}, arch={row['hidden_dims']}, \"\n",
    "              f\"dropout={row['dropout']}, lr={row['lr']}, wd={row['weight_decay']}\")\n",
    "\n",
    "\n",
    "def analyze_by_category(df):\n",
    "    \"\"\"Analyze results by different configuration categories\"\"\"\n",
    "    print(f\"\\n\" + \"=\"*120)\n",
    "    print(\"DETAILED ANALYSIS BY CONFIGURATION\")\n",
    "    print(\"=\"*120)\n",
    "    \n",
    "    # Helper function for pretty printing\n",
    "    def print_analysis(group_col, title):\n",
    "        print(f\"\\n{title}:\")\n",
    "        print(\"-\"*120)\n",
    "        analysis = df.groupby(group_col).agg({\n",
    "            'test_f1': ['count', 'mean', 'std', 'min', 'max'],\n",
    "            'overfit_gap': ['mean', 'std'],\n",
    "            'test_precision': 'mean',\n",
    "            'test_recall': 'mean',\n",
    "            'test_roc_auc': 'mean',\n",
    "            'best_epoch': 'mean'\n",
    "        }).round(4)\n",
    "        print(analysis)\n",
    "        \n",
    "        # Statistical test if enough groups\n",
    "        if len(df[group_col].unique()) >= 2:\n",
    "            groups = [group['test_f1'].values for name, group in df.groupby(group_col)]\n",
    "            if len(groups) >= 2 and all(len(g) >= 2 for g in groups[:2]):\n",
    "                statistic, pvalue = stats.f_oneway(*groups)\n",
    "                print(f\"\\nANOVA F-statistic: {statistic:.4f}, p-value: {pvalue:.4e}\")\n",
    "                if pvalue < 0.05:\n",
    "                    print(\"  â†’ Statistically significant differences detected!\")\n",
    "                else:\n",
    "                    print(\"  â†’ No significant differences (might just be noise)\")\n",
    "    \n",
    "    # Run analyses\n",
    "    print_analysis('input_type', '1. BY INPUT TYPE')\n",
    "    print_analysis('dropout', '2. BY DROPOUT RATE')\n",
    "    print_analysis('lr', '3. BY LEARNING RATE')\n",
    "    print_analysis('weight_decay', '4. BY WEIGHT DECAY')\n",
    "    print_analysis('batch_size', '5. BY BATCH SIZE')\n",
    "    print_analysis('num_layers', '6. BY NETWORK DEPTH')\n",
    "    print_analysis('patience', '7. BY EARLY STOPPING PATIENCE')\n",
    "    \n",
    "    # Architecture size bins\n",
    "    df['arch_size'] = pd.cut(df['total_hidden_units'], \n",
    "                              bins=[0, 300, 600, 900, 1500, 5000],\n",
    "                              labels=['tiny', 'small', 'medium', 'large', 'huge'])\n",
    "    print_analysis('arch_size', '8. BY ARCHITECTURE SIZE')\n",
    "\n",
    "\n",
    "def deep_dive_concat(df):\n",
    "    \"\"\"Deep analysis specifically for concat experiments\"\"\"\n",
    "    print(f\"\\n\" + \"=\"*120)\n",
    "    print(\"DEEP DIVE: CONCAT INPUT EXPERIMENTS\")\n",
    "    print(\"=\"*120)\n",
    "    \n",
    "    concat_df = df[df['input_type'] == 'concat'].copy()\n",
    "    \n",
    "    if len(concat_df) == 0:\n",
    "        print(\"No concat experiments found!\")\n",
    "        return\n",
    "    \n",
    "    print(f\"\\nTotal concat experiments: {len(concat_df)}\")\n",
    "    print(f\"Best F1: {concat_df['test_f1'].max():.4f}\")\n",
    "    print(f\"Worst F1: {concat_df['test_f1'].min():.4f}\")\n",
    "    print(f\"Mean F1: {concat_df['test_f1'].mean():.4f} Â± {concat_df['test_f1'].std():.4f}\")\n",
    "    print(f\"Median overfit gap: {concat_df['overfit_gap'].median():.4f}\")\n",
    "    \n",
    "    # Find optimal hyperparameters\n",
    "    print(\"\\n\" + \"-\"*120)\n",
    "    print(\"OPTIMAL HYPERPARAMETERS FOR CONCAT:\")\n",
    "    print(\"-\"*120)\n",
    "    \n",
    "    for param in ['dropout', 'lr', 'weight_decay', 'batch_size', 'hidden_dims']:\n",
    "        best_idx = concat_df['test_f1'].idxmax()\n",
    "        top_5 = concat_df.nlargest(5, 'test_f1')\n",
    "        \n",
    "        print(f\"\\n{param.upper()}:\")\n",
    "        print(f\"  Best single model: {concat_df.loc[best_idx, param]}\")\n",
    "        print(f\"  Top 5 average: {top_5[param].mode().values if param == 'hidden_dims' else top_5[param].mean()}\")\n",
    "        \n",
    "        # Show distribution\n",
    "        if param != 'hidden_dims':\n",
    "            value_counts = top_5[param].value_counts()\n",
    "            print(f\"  Distribution in top 5:\")\n",
    "            for val, count in value_counts.items():\n",
    "                print(f\"    {val}: {count}/5\")\n",
    "    \n",
    "    # Correlation analysis\n",
    "    print(\"\\n\" + \"-\"*120)\n",
    "    print(\"HYPERPARAMETER CORRELATIONS WITH F1:\")\n",
    "    print(\"-\"*120)\n",
    "    \n",
    "    numeric_params = ['dropout', 'lr', 'weight_decay', 'batch_size', 'total_hidden_units', 'num_layers']\n",
    "    correlations = {}\n",
    "    \n",
    "    for param in numeric_params:\n",
    "        if concat_df[param].nunique() > 1:\n",
    "            corr = concat_df[param].corr(concat_df['test_f1'])\n",
    "            correlations[param] = corr\n",
    "            print(f\"{param:>20}: {corr:>7.4f}\")\n",
    "    \n",
    "    # Find sweet spots\n",
    "    print(\"\\n\" + \"-\"*120)\n",
    "    print(\"SWEET SPOT RANGES (values where F1 > 0.80):\")\n",
    "    print(\"-\"*120)\n",
    "    \n",
    "    high_performers = concat_df[concat_df['test_f1'] > 0.80]\n",
    "    if len(high_performers) > 0:\n",
    "        for param in ['dropout', 'lr', 'weight_decay']:\n",
    "            if high_performers[param].nunique() > 1:\n",
    "                print(f\"{param}: [{high_performers[param].min():.6f}, {high_performers[param].max():.6f}]\")\n",
    "    else:\n",
    "        print(\"No models achieved F1 > 0.80\")\n",
    "\n",
    "\n",
    "def analyze_regularization_tradeoffs(df):\n",
    "    \"\"\"Analyze the relationship between regularization and performance\"\"\"\n",
    "    print(f\"\\n\" + \"=\"*120)\n",
    "    print(\"REGULARIZATION ANALYSIS\")\n",
    "    print(\"=\"*120)\n",
    "    \n",
    "    # Define regularization strength\n",
    "    df['reg_strength'] = df['dropout'] + np.log10(df['weight_decay'] + 1e-10) / 5\n",
    "    \n",
    "    # Bin into categories\n",
    "    df['reg_category'] = pd.cut(df['reg_strength'], \n",
    "                                 bins=[-np.inf, -1, 0, 1, np.inf],\n",
    "                                 labels=['minimal', 'light', 'moderate', 'heavy'])\n",
    "    \n",
    "    print(\"\\nPerformance by regularization strength:\")\n",
    "    reg_analysis = df.groupby('reg_category').agg({\n",
    "        'test_f1': ['count', 'mean', 'std', 'max'],\n",
    "        'overfit_gap': ['mean', 'std'],\n",
    "        'test_precision': 'mean',\n",
    "        'test_recall': 'mean',\n",
    "    }).round(4)\n",
    "    print(reg_analysis)\n",
    "    \n",
    "    # Overfitting analysis\n",
    "    print(\"\\n\" + \"-\"*120)\n",
    "    print(\"OVERFITTING STATISTICS:\")\n",
    "    print(\"-\"*120)\n",
    "    print(f\"Models with overfit_gap > 0.15: {(df['overfit_gap'] > 0.15).sum()}/{len(df)}\")\n",
    "    print(f\"Models with overfit_gap < 0.05: {(df['overfit_gap'] < 0.05).sum()}/{len(df)}\")\n",
    "    print(f\"Models with negative gap (test > train): {(df['overfit_gap'] < 0).sum()}/{len(df)}\")\n",
    "    \n",
    "    # Best regularization strategy\n",
    "    well_generalized = df[df['overfit_gap'].abs() < 0.10]\n",
    "    if len(well_generalized) > 0:\n",
    "        best_generalized = well_generalized.loc[well_generalized['test_f1'].idxmax()]\n",
    "        print(f\"\\nBest well-generalized model (|gap| < 0.10):\")\n",
    "        print(f\"  {best_generalized['experiment']}\")\n",
    "        print(f\"  F1: {best_generalized['test_f1']:.4f}, Gap: {best_generalized['overfit_gap']:.4f}\")\n",
    "        print(f\"  Config: dropout={best_generalized['dropout']}, wd={best_generalized['weight_decay']}\")\n",
    "\n",
    "\n",
    "def analyze_precision_recall_tradeoff(df):\n",
    "    \"\"\"Analyze precision-recall tradeoff and identify Pareto frontier\"\"\"\n",
    "    print(f\"\\n\" + \"=\"*120)\n",
    "    print(\"PRECISION-RECALL TRADEOFF ANALYSIS\")\n",
    "    print(\"=\"*120)\n",
    "    \n",
    "    # Sort by F1 and show precision-recall balance\n",
    "    print(\"\\nTop 10 models by F1 with precision-recall breakdown:\")\n",
    "    print(\"-\"*120)\n",
    "    top_10 = df.nlargest(10, 'test_f1')\n",
    "    \n",
    "    for idx, (_, row) in enumerate(top_10.iterrows(), 1):\n",
    "        prec_rec_diff = abs(row['test_precision'] - row['test_recall'])\n",
    "        balance = \"balanced\" if prec_rec_diff < 0.05 else (\"precision-biased\" if row['test_precision'] > row['test_recall'] else \"recall-biased\")\n",
    "        print(f\"{idx:>2}. {row['experiment']:<35} F1:{row['test_f1']:.4f}  \"\n",
    "              f\"P:{row['test_precision']:.4f}  R:{row['test_recall']:.4f}  [{balance}]\")\n",
    "    \n",
    "    # Identify Pareto-optimal models\n",
    "    print(\"\\n\" + \"-\"*120)\n",
    "    print(\"PARETO FRONTIER (models where you can't improve one metric without hurting the other):\")\n",
    "    print(\"-\"*120)\n",
    "    \n",
    "    pareto_models = []\n",
    "    for idx, row in df.iterrows():\n",
    "        is_pareto = True\n",
    "        for _, other in df.iterrows():\n",
    "            if (other['test_precision'] >= row['test_precision'] and \n",
    "                other['test_recall'] >= row['test_recall'] and\n",
    "                (other['test_precision'] > row['test_precision'] or other['test_recall'] > row['test_recall'])):\n",
    "                is_pareto = False\n",
    "                break\n",
    "        if is_pareto:\n",
    "            pareto_models.append(row)\n",
    "    \n",
    "    pareto_df = pd.DataFrame(pareto_models).sort_values('test_f1', ascending=False)\n",
    "    print(f\"\\nFound {len(pareto_df)} Pareto-optimal models:\")\n",
    "    for _, row in pareto_df.head(10).iterrows():\n",
    "        print(f\"  {row['experiment']:<35} P:{row['test_precision']:.4f}  R:{row['test_recall']:.4f}  F1:{row['test_f1']:.4f}\")\n",
    "\n",
    "\n",
    "def analyze_seed_variance(df):\n",
    "    \"\"\"Analyze variance across different random seeds\"\"\"\n",
    "    print(f\"\\n\" + \"=\"*120)\n",
    "    print(\"RANDOM SEED VARIANCE ANALYSIS\")\n",
    "    print(\"=\"*120)\n",
    "    \n",
    "    # Find experiments with multiple seeds\n",
    "    df['exp_base'] = df['experiment'].str.replace(r'_seed\\d+', '', regex=True)\n",
    "    seed_groups = df.groupby('exp_base').filter(lambda x: len(x) > 1)\n",
    "    \n",
    "    if len(seed_groups) == 0:\n",
    "        print(\"\\nNo replicated experiments found (need same config with different seeds)\")\n",
    "        return\n",
    "    \n",
    "    print(f\"\\nFound {seed_groups['exp_base'].nunique()} configurations with multiple seeds:\")\n",
    "    print(\"-\"*120)\n",
    "    \n",
    "    for exp_base, group in seed_groups.groupby('exp_base'):\n",
    "        print(f\"\\n{exp_base}:\")\n",
    "        print(f\"  Runs: {len(group)}\")\n",
    "        print(f\"  F1: {group['test_f1'].mean():.4f} Â± {group['test_f1'].std():.4f} \"\n",
    "              f\"(range: [{group['test_f1'].min():.4f}, {group['test_f1'].max():.4f}])\")\n",
    "        print(f\"  Precision: {group['test_precision'].mean():.4f} Â± {group['test_precision'].std():.4f}\")\n",
    "        print(f\"  Recall: {group['test_recall'].mean():.4f} Â± {group['test_recall'].std():.4f}\")\n",
    "        print(f\"  Overfit gap: {group['overfit_gap'].mean():.4f} Â± {group['overfit_gap'].std():.4f}\")\n",
    "        \n",
    "        if group['test_f1'].std() > 0.02:\n",
    "            print(f\"  âš ï¸  High variance detected! Results may be unstable.\")\n",
    "\n",
    "\n",
    "def plot_extended_analysis(df, save_dir):\n",
    "    \"\"\"Create comprehensive visualizations\"\"\"\n",
    "    fig = plt.figure(figsize=(24, 18))\n",
    "    \n",
    "    # Sort by F1\n",
    "    df_sorted = df.sort_values('test_f1', ascending=True)\n",
    "    \n",
    "    # 1. Top 20 models comparison\n",
    "    ax1 = plt.subplot(4, 4, 1)\n",
    "    top_20 = df_sorted.tail(20)\n",
    "    y_pos = np.arange(len(top_20))\n",
    "    ax1.barh(y_pos, top_20['test_f1'], alpha=0.6, label='F1')\n",
    "    ax1.barh(y_pos, top_20['test_precision'], alpha=0.6, label='Precision')\n",
    "    ax1.barh(y_pos, top_20['test_recall'], alpha=0.6, label='Recall')\n",
    "    ax1.set_yticks(y_pos)\n",
    "    ax1.set_yticklabels([e.replace('exp_', '').replace('concat_', 'c_')[:20] for e in top_20['experiment']], fontsize=7)\n",
    "    ax1.set_xlabel('Score')\n",
    "    ax1.set_title('Top 20 Models')\n",
    "    ax1.legend(fontsize=7)\n",
    "    ax1.grid(axis='x', alpha=0.3)\n",
    "    \n",
    "    # 2. Overfitting scatter\n",
    "    ax2 = plt.subplot(4, 4, 2)\n",
    "    scatter = ax2.scatter(df['overfit_gap'], df['test_f1'], \n",
    "                         c=df['dropout'], s=100, alpha=0.6, cmap='coolwarm')\n",
    "    ax2.axvline(x=0, color='black', linestyle='--', alpha=0.3)\n",
    "    ax2.set_xlabel('Overfitting Gap')\n",
    "    ax2.set_ylabel('Test F1')\n",
    "    ax2.set_title('Overfitting vs Performance (color=dropout)')\n",
    "    ax2.grid(alpha=0.3)\n",
    "    plt.colorbar(scatter, ax=ax2, label='Dropout')\n",
    "    \n",
    "    # 3. Precision-Recall frontier\n",
    "    ax3 = plt.subplot(4, 4, 3)\n",
    "    ax3.scatter(df['test_recall'], df['test_precision'], \n",
    "               c=df['test_f1'], s=100, alpha=0.6, cmap='viridis')\n",
    "    # Plot top 5\n",
    "    top_5 = df.nlargest(5, 'test_f1')\n",
    "    ax3.scatter(top_5['test_recall'], top_5['test_precision'], \n",
    "               c='red', s=200, marker='*', edgecolors='black', linewidths=2, label='Top 5')\n",
    "    ax3.set_xlabel('Recall')\n",
    "    ax3.set_ylabel('Precision')\n",
    "    ax3.set_title('Precision-Recall Space (color=F1)')\n",
    "    ax3.legend()\n",
    "    ax3.grid(alpha=0.3)\n",
    "    \n",
    "    # 4. Input type comparison (boxplot)\n",
    "    ax4 = plt.subplot(4, 4, 4)\n",
    "    input_types = [df[df['input_type']==it]['test_f1'].values for it in df['input_type'].unique()]\n",
    "    ax4.boxplot(input_types, labels=df['input_type'].unique())\n",
    "    ax4.set_ylabel('Test F1')\n",
    "    ax4.set_title('F1 Distribution by Input Type')\n",
    "    ax4.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # 5. Dropout effect (concat only)\n",
    "    ax5 = plt.subplot(4, 4, 5)\n",
    "    concat_df = df[df['input_type'] == 'concat']\n",
    "    if len(concat_df) > 0:\n",
    "        dropout_stats = concat_df.groupby('dropout').agg({'test_f1': ['mean', 'std', 'count']})\n",
    "        dropout_stats = dropout_stats[dropout_stats[('test_f1', 'count')] >= 2]  # Only show if >= 2 samples\n",
    "        if len(dropout_stats) > 0:\n",
    "            ax5.errorbar(dropout_stats.index, \n",
    "                        dropout_stats[('test_f1', 'mean')],\n",
    "                        yerr=dropout_stats[('test_f1', 'std')],\n",
    "                        marker='o', capsize=5, linewidth=2)\n",
    "            ax5.set_xlabel('Dropout Rate')\n",
    "            ax5.set_ylabel('Mean Test F1 (concat)')\n",
    "            ax5.set_title('Dropout Effect on Concat Models')\n",
    "            ax5.grid(alpha=0.3)\n",
    "    \n",
    "    # 6. Weight decay effect (concat only)\n",
    "    ax6 = plt.subplot(4, 4, 6)\n",
    "    if len(concat_df) > 0:\n",
    "        wd_data = concat_df[concat_df['weight_decay'] > 0]\n",
    "        if len(wd_data) > 0:\n",
    "            ax6.scatter(wd_data['weight_decay'], wd_data['test_f1'], s=100, alpha=0.6)\n",
    "            ax6.set_xscale('log')\n",
    "            ax6.set_xlabel('Weight Decay (log scale)')\n",
    "            ax6.set_ylabel('Test F1')\n",
    "            ax6.set_title('Weight Decay Effect (concat)')\n",
    "            ax6.grid(alpha=0.3)\n",
    "    \n",
    "    # 7. Learning rate effect\n",
    "    ax7 = plt.subplot(4, 4, 7)\n",
    "    lr_stats = df.groupby('lr').agg({'test_f1': ['mean', 'std', 'count']})\n",
    "    lr_stats = lr_stats[lr_stats[('test_f1', 'count')] >= 2]\n",
    "    if len(lr_stats) > 0:\n",
    "        ax7.errorbar(lr_stats.index, \n",
    "                    lr_stats[('test_f1', 'mean')],\n",
    "                    yerr=lr_stats[('test_f1', 'std')],\n",
    "                    marker='o', capsize=5, linewidth=2)\n",
    "        ax7.set_xscale('log')\n",
    "        ax7.set_xlabel('Learning Rate (log scale)')\n",
    "        ax7.set_ylabel('Mean Test F1')\n",
    "        ax7.set_title('Learning Rate Effect')\n",
    "        ax7.grid(alpha=0.3)\n",
    "    \n",
    "    # 8. Architecture size vs performance\n",
    "    ax8 = plt.subplot(4, 4, 8)\n",
    "    ax8.scatter(df['total_hidden_units'], df['test_f1'], \n",
    "               c=df['overfit_gap'], s=100, alpha=0.6, cmap='RdYlGn_r')\n",
    "    ax8.set_xlabel('Total Hidden Units')\n",
    "    ax8.set_ylabel('Test F1')\n",
    "    ax8.set_title('Model Size vs Performance (color=overfit)')\n",
    "    ax8.grid(alpha=0.3)\n",
    "    \n",
    "    # 9. Batch size effect\n",
    "    ax9 = plt.subplot(4, 4, 9)\n",
    "    batch_stats = df.groupby('batch_size').agg({'test_f1': ['mean', 'std', 'count']})\n",
    "    batch_stats = batch_stats[batch_stats[('test_f1', 'count')] >= 2]\n",
    "    if len(batch_stats) > 0:\n",
    "        ax9.errorbar(batch_stats.index, \n",
    "                    batch_stats[('test_f1', 'mean')],\n",
    "                    yerr=batch_stats[('test_f1', 'std')],\n",
    "                    marker='o', capsize=5, linewidth=2)\n",
    "        ax9.set_xlabel('Batch Size')\n",
    "        ax9.set_ylabel('Mean Test F1')\n",
    "        ax9.set_title('Batch Size Effect')\n",
    "        ax9.grid(alpha=0.3)\n",
    "    \n",
    "    # 10. Convergence speed\n",
    "    ax10 = plt.subplot(4, 4, 10)\n",
    "    ax10.scatter(df['best_epoch'], df['test_f1'], s=100, alpha=0.6)\n",
    "    ax10.set_xlabel('Epoch of Best Validation')\n",
    "    ax10.set_ylabel('Test F1')\n",
    "    ax10.set_title('Convergence Speed vs Performance')\n",
    "    ax10.grid(alpha=0.3)\n",
    "    \n",
    "    # 11. False positive vs false negative rates\n",
    "    ax11 = plt.subplot(4, 4, 11)\n",
    "    ax11.scatter(df['false_positive_rate'], df['false_negative_rate'],\n",
    "                c=df['test_f1'], s=100, alpha=0.6, cmap='viridis')\n",
    "    ax11.set_xlabel('False Positive Rate')\n",
    "    ax11.set_ylabel('False Negative Rate')\n",
    "    ax11.set_title('Error Types (color=F1)')\n",
    "    ax11.grid(alpha=0.3)\n",
    "    \n",
    "    # 12. Regularization strength heatmap (dropout vs weight decay)\n",
    "    ax12 = plt.subplot(4, 4, 12)\n",
    "    concat_pivot = concat_df.pivot_table(values='test_f1', \n",
    "                                         index='dropout', \n",
    "                                         columns='weight_decay',\n",
    "                                         aggfunc='mean')\n",
    "    if not concat_pivot.empty:\n",
    "        sns.heatmap(concat_pivot, annot=True, fmt='.3f', cmap='RdYlGn', ax=ax12, cbar_kws={'label': 'F1'})\n",
    "        ax12.set_title('Concat: Dropout Ã— Weight Decay')\n",
    "    \n",
    "    # 13. Architecture depth vs width\n",
    "    ax13 = plt.subplot(4, 4, 13)\n",
    "    ax13.scatter(df['num_layers'], df['max_layer_size'],\n",
    "                c=df['test_f1'], s=100, alpha=0.6, cmap='viridis')\n",
    "    ax13.set_xlabel('Number of Layers')\n",
    "    ax13.set_ylabel('Max Layer Size')\n",
    "    ax13.set_title('Architecture Shape (color=F1)')\n",
    "    ax13.grid(alpha=0.3)\n",
    "    \n",
    "    # 14. Top 10 confusion matrices (simplified)\n",
    "    ax14 = plt.subplot(4, 4, 14)\n",
    "    top_10_models = df.nlargest(10, 'test_f1')\n",
    "    fp_rates = top_10_models['false_positive_rate'].values\n",
    "    fn_rates = top_10_models['false_negative_rate'].values\n",
    "    ax14.scatter(fp_rates, fn_rates, s=200, alpha=0.6)\n",
    "    for i, exp in enumerate(top_10_models['experiment'].values):\n",
    "        ax14.annotate(f\"{i+1}\", (fp_rates[i], fn_rates[i]), \n",
    "                     ha='center', va='center', fontsize=8, fontweight='bold')\n",
    "    ax14.set_xlabel('False Positive Rate')\n",
    "    ax14.set_ylabel('False Negative Rate')\n",
    "    ax14.set_title('Top 10 Models: Error Rates')\n",
    "    ax14.grid(alpha=0.3)\n",
    "    \n",
    "    # 15. Seed variance (if available)\n",
    "    ax15 = plt.subplot(4, 4, 15)\n",
    "    df['exp_base'] = df['experiment'].str.replace(r'_seed\\d+', '', regex=True)\n",
    "    seed_groups = df.groupby('exp_base').filter(lambda x: len(x) > 1)\n",
    "    if len(seed_groups) > 0:\n",
    "        variance_data = seed_groups.groupby('exp_base')['test_f1'].agg(['mean', 'std'])\n",
    "        variance_data = variance_data.sort_values('mean', ascending=False).head(10)\n",
    "        y_pos = np.arange(len(variance_data))\n",
    "        ax15.barh(y_pos, variance_data['mean'], xerr=variance_data['std'], capsize=5)\n",
    "        ax15.set_yticks(y_pos)\n",
    "        ax15.set_yticklabels([e[:25] for e in variance_data.index], fontsize=7)\n",
    "        ax15.set_xlabel('F1 Score')\n",
    "        ax15.set_title('Seed Variance (mean Â± std)')\n",
    "        ax15.grid(axis='x', alpha=0.3)\n",
    "    else:\n",
    "        ax15.text(0.5, 0.5, 'No replicated experiments', \n",
    "                 ha='center', va='center', transform=ax15.transAxes)\n",
    "        ax15.set_title('Seed Variance')\n",
    "    \n",
    "    # 16. Performance improvement over baseline\n",
    "    ax16 = plt.subplot(4, 4, 16)\n",
    "    baseline_f1 = df[df['experiment'].str.contains('baseline')]['test_f1'].mean()\n",
    "    df['improvement'] = df['test_f1'] - baseline_f1\n",
    "    top_improvements = df.nlargest(15, 'improvement')\n",
    "    y_pos = np.arange(len(top_improvements))\n",
    "    colors = ['green' if x > 0 else 'red' for x in top_improvements['improvement']]\n",
    "    ax16.barh(y_pos, top_improvements['improvement'], color=colors, alpha=0.6)\n",
    "    ax16.set_yticks(y_pos)\n",
    "    ax16.set_yticklabels([e.replace('exp_', '')[:20] for e in top_improvements['experiment']], fontsize=7)\n",
    "    ax16.axvline(x=0, color='black', linestyle='--', linewidth=1)\n",
    "    ax16.set_xlabel('F1 Improvement over Baseline')\n",
    "    ax16.set_title('Top 15 Improvements')\n",
    "    ax16.grid(axis='x', alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_dir / 'extended_analysis.png', dpi=300, bbox_inches='tight')\n",
    "    print(f\"\\nExtended visualization saved to {save_dir / 'extended_analysis.png'}\")\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def plot_concat_deep_dive(df, save_dir):\n",
    "    \"\"\"Detailed visualization specifically for concat experiments\"\"\"\n",
    "    concat_df = df[df['input_type'] == 'concat'].copy()\n",
    "    \n",
    "    if len(concat_df) < 5:\n",
    "        print(\"\\nNot enough concat experiments for deep dive (need at least 5)\")\n",
    "        return\n",
    "    \n",
    "    fig = plt.figure(figsize=(20, 12))\n",
    "    \n",
    "    # 1. F1 distribution\n",
    "    ax1 = plt.subplot(3, 3, 1)\n",
    "    ax1.hist(concat_df['test_f1'], bins=20, alpha=0.7, edgecolor='black')\n",
    "    ax1.axvline(concat_df['test_f1'].mean(), color='red', linestyle='--', linewidth=2, label='Mean')\n",
    "    ax1.axvline(concat_df['test_f1'].median(), color='green', linestyle='--', linewidth=2, label='Median')\n",
    "    ax1.set_xlabel('Test F1')\n",
    "    ax1.set_ylabel('Count')\n",
    "    ax1.set_title(f'F1 Distribution (n={len(concat_df)})')\n",
    "    ax1.legend()\n",
    "    ax1.grid(alpha=0.3)\n",
    "    \n",
    "    # 2. 3D scatter: dropout Ã— weight_decay Ã— F1\n",
    "    ax2 = plt.subplot(3, 3, 2, projection='3d')\n",
    "    scatter = ax2.scatter(concat_df['dropout'], \n",
    "                         np.log10(concat_df['weight_decay'] + 1e-10),\n",
    "                         concat_df['test_f1'],\n",
    "                         c=concat_df['test_f1'], s=100, alpha=0.6, cmap='viridis')\n",
    "    ax2.set_xlabel('Dropout')\n",
    "    ax2.set_ylabel('log10(Weight Decay)')\n",
    "    ax2.set_zlabel('Test F1')\n",
    "    ax2.set_title('Regularization Space')\n",
    "    plt.colorbar(scatter, ax=ax2, shrink=0.5)\n",
    "    \n",
    "    # 3. Learning rate vs F1\n",
    "    ax3 = plt.subplot(3, 3, 3)\n",
    "    for lr in sorted(concat_df['lr'].unique()):\n",
    "        lr_data = concat_df[concat_df['lr'] == lr]\n",
    "        ax3.scatter([lr]*len(lr_data), lr_data['test_f1'], s=100, alpha=0.6, label=f'lr={lr}')\n",
    "    ax3.set_xscale('log')\n",
    "    ax3.set_xlabel('Learning Rate')\n",
    "    ax3.set_ylabel('Test F1')\n",
    "    ax3.set_title('Learning Rate Landscape')\n",
    "    ax3.legend(fontsize=8)\n",
    "    ax3.grid(alpha=0.3)\n",
    "    \n",
    "    # 4. Architecture size exploration\n",
    "    ax4 = plt.subplot(3, 3, 4)\n",
    "    ax4.scatter(concat_df['total_hidden_units'], concat_df['test_f1'], \n",
    "               s=concat_df['num_layers']*50, alpha=0.6, c=concat_df['num_layers'], cmap='plasma')\n",
    "    ax4.set_xlabel('Total Hidden Units')\n",
    "    ax4.set_ylabel('Test F1')\n",
    "    ax4.set_title('Architecture Size (size=depth)')\n",
    "    ax4.grid(alpha=0.3)\n",
    "    \n",
    "    # 5. Overfitting by regularization level\n",
    "    ax5 = plt.subplot(3, 3, 5)\n",
    "    concat_df['total_reg'] = concat_df['dropout'] + np.log10(concat_df['weight_decay'] + 1e-9)\n",
    "    ax5.scatter(concat_df['total_reg'], concat_df['overfit_gap'], \n",
    "               c=concat_df['test_f1'], s=100, alpha=0.6, cmap='viridis')\n",
    "    ax5.axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
    "    ax5.set_xlabel('Total Regularization (dropout + log10(wd))')\n",
    "    ax5.set_ylabel('Overfitting Gap')\n",
    "    ax5.set_title('Regularization vs Overfitting')\n",
    "    ax5.grid(alpha=0.3)\n",
    "    \n",
    "    # 6. Batch size effect\n",
    "    ax6 = plt.subplot(3, 3, 6)\n",
    "    if concat_df['batch_size'].nunique() > 1:\n",
    "        batch_grouped = concat_df.groupby('batch_size').agg({\n",
    "            'test_f1': ['mean', 'std'],\n",
    "            'overfit_gap': 'mean'\n",
    "        })\n",
    "        ax6_twin = ax6.twinx()\n",
    "        ax6.errorbar(batch_grouped.index, batch_grouped[('test_f1', 'mean')],\n",
    "                    yerr=batch_grouped[('test_f1', 'std')], \n",
    "                    marker='o', color='blue', capsize=5, label='F1')\n",
    "        ax6_twin.plot(batch_grouped.index, batch_grouped[('overfit_gap', 'mean')],\n",
    "                     marker='s', color='red', label='Overfit Gap')\n",
    "        ax6.set_xlabel('Batch Size')\n",
    "        ax6.set_ylabel('Test F1', color='blue')\n",
    "        ax6_twin.set_ylabel('Overfit Gap', color='red')\n",
    "        ax6.set_title('Batch Size Impact')\n",
    "        ax6.tick_params(axis='y', labelcolor='blue')\n",
    "        ax6_twin.tick_params(axis='y', labelcolor='red')\n",
    "        ax6.grid(alpha=0.3)\n",
    "    \n",
    "    # 7. Top 10 architectures\n",
    "    ax7 = plt.subplot(3, 3, 7)\n",
    "    top_10_concat = concat_df.nlargest(10, 'test_f1')\n",
    "    y_pos = np.arange(len(top_10_concat))\n",
    "    ax7.barh(y_pos, top_10_concat['test_f1'], alpha=0.7)\n",
    "    ax7.set_yticks(y_pos)\n",
    "    ax7.set_yticklabels([f\"{row['hidden_dims']}\\nd={row['dropout']}\" \n",
    "                         for _, row in top_10_concat.iterrows()], fontsize=7)\n",
    "    ax7.set_xlabel('Test F1')\n",
    "    ax7.set_title('Top 10 Concat Architectures')\n",
    "    ax7.grid(axis='x', alpha=0.3)\n",
    "    \n",
    "    # 8. Patience effect\n",
    "    ax8 = plt.subplot(3, 3, 8)\n",
    "    if concat_df['patience'].nunique() > 1:\n",
    "        patience_grouped = concat_df.groupby('patience').agg({\n",
    "            'test_f1': 'mean',\n",
    "            'best_epoch': 'mean'\n",
    "        })\n",
    "        ax8_twin = ax8.twinx()\n",
    "        ax8.plot(patience_grouped.index, patience_grouped['test_f1'],\n",
    "                marker='o', color='blue', linewidth=2, label='F1')\n",
    "        ax8_twin.plot(patience_grouped.index, patience_grouped['best_epoch'],\n",
    "                     marker='s', color='orange', linewidth=2, label='Best Epoch')\n",
    "        ax8.set_xlabel('Early Stopping Patience')\n",
    "        ax8.set_ylabel('Mean Test F1', color='blue')\n",
    "        ax8_twin.set_ylabel('Mean Best Epoch', color='orange')\n",
    "        ax8.set_title('Patience Impact')\n",
    "        ax8.tick_params(axis='y', labelcolor='blue')\n",
    "        ax8_twin.tick_params(axis='y', labelcolor='orange')\n",
    "        ax8.grid(alpha=0.3)\n",
    "    \n",
    "    # 9. Performance correlation matrix\n",
    "    ax9 = plt.subplot(3, 3, 9)\n",
    "    corr_cols = ['test_f1', 'test_precision', 'test_recall', 'overfit_gap', \n",
    "                 'dropout', 'total_hidden_units', 'best_epoch']\n",
    "    corr_matrix = concat_df[corr_cols].corr()\n",
    "    sns.heatmap(corr_matrix, annot=True, fmt='.2f', cmap='coolwarm', \n",
    "                center=0, ax=ax9, cbar_kws={'label': 'Correlation'})\n",
    "    ax9.set_title('Feature Correlation Matrix')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_dir / 'concat_deep_dive.png', dpi=300, bbox_inches='tight')\n",
    "    print(f\"Concat deep dive saved to {save_dir / 'concat_deep_dive.png'}\")\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def plot_confusion_matrices(results, df, save_dir):\n",
    "    \"\"\"Plot confusion matrices for different categories of models\"\"\"\n",
    "    \n",
    "    # Get top performers, most generalizable, high precision, high recall\n",
    "    categories = {\n",
    "        'Top 3 F1': df.nlargest(3, 'test_f1')['experiment'].tolist(),\n",
    "        'Most Generalizable': df.nsmallest(3, lambda x: abs(x['overfit_gap']))['experiment'].tolist(),\n",
    "        'High Precision': df.nlargest(3, 'test_precision')['experiment'].tolist(),\n",
    "        'High Recall': df.nlargest(3, 'test_recall')['experiment'].tolist(),\n",
    "    }\n",
    "    \n",
    "    fig, axes = plt.subplots(4, 3, figsize=(15, 18))\n",
    "    \n",
    "    for row_idx, (category, exp_names) in enumerate(categories.items()):\n",
    "        for col_idx, exp_name in enumerate(exp_names):\n",
    "            ax = axes[row_idx, col_idx]\n",
    "            \n",
    "            # Find the result\n",
    "            result = next((r for r in results if r['experiment_name'] == exp_name), None)\n",
    "            if result is None:\n",
    "                continue\n",
    "            \n",
    "            cm = np.array(result['confusion_matrix'])\n",
    "            \n",
    "            # Plot heatmap\n",
    "            sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax,\n",
    "                       xticklabels=['Neg', 'Pos'], yticklabels=['Neg', 'Pos'],\n",
    "                       cbar_kws={'label': 'Count'})\n",
    "            \n",
    "            # Add metrics to title\n",
    "            f1 = result['test_f1']\n",
    "            prec = result['test_precision']\n",
    "            rec = result['test_recall']\n",
    "            \n",
    "            title = f\"{exp_name.replace('exp_', '').replace('concat_', 'c_')[:25]}\\n\"\n",
    "            title += f\"F1:{f1:.3f} P:{prec:.3f} R:{rec:.3f}\"\n",
    "            ax.set_title(title, fontsize=9)\n",
    "            ax.set_ylabel('True')\n",
    "            ax.set_xlabel('Predicted')\n",
    "    \n",
    "    # Add category labels\n",
    "    for row_idx, category in enumerate(categories.keys()):\n",
    "        fig.text(0.02, 0.88 - row_idx*0.23, category, \n",
    "                rotation=90, fontsize=14, fontweight='bold',\n",
    "                va='center', ha='center')\n",
    "    \n",
    "    plt.tight_layout(rect=[0.03, 0, 1, 1])\n",
    "    plt.savefig(save_dir / 'confusion_matrices_by_category.png', dpi=300, bbox_inches='tight')\n",
    "    print(f\"Confusion matrices saved to {save_dir / 'confusion_matrices_by_category.png'}\")\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def generate_recommendations(df):\n",
    "    \"\"\"Generate detailed recommendations based on all experiments\"\"\"\n",
    "    print(f\"\\n\" + \"=\"*120)\n",
    "    print(\"DETAILED RECOMMENDATIONS & INSIGHTS\")\n",
    "    print(\"=\"*120)\n",
    "    \n",
    "    best_overall = df.loc[df['test_f1'].idxmax()]\n",
    "    least_overfit = df.loc[df['overfit_gap'].abs().idxmin()]\n",
    "    best_recall = df.loc[df['test_recall'].idxmax()]\n",
    "    best_precision = df.loc[df['test_precision'].idxmax()]\n",
    "    best_auc = df.loc[df['test_roc_auc'].idxmax()]\n",
    "    \n",
    "    print(f\"\\n{'='*120}\")\n",
    "    print(\"1. PRODUCTION DEPLOYMENT RECOMMENDATIONS\")\n",
    "    print(f\"{'='*120}\")\n",
    "    \n",
    "    print(f\"\\nðŸ† Best Overall Model (maximize F1):\")\n",
    "    print(f\"   {best_overall['experiment']}\")\n",
    "    print(f\"   â€¢ F1: {best_overall['test_f1']:.4f} | Precision: {best_overall['test_precision']:.4f} | Recall: {best_overall['test_recall']:.4f}\")\n",
    "    print(f\"   â€¢ Config: {best_overall['input_type']}, {best_overall['hidden_dims']}\")\n",
    "    print(f\"   â€¢ Regularization: dropout={best_overall['dropout']}, weight_decay={best_overall['weight_decay']}\")\n",
    "    print(f\"   â€¢ Training: lr={best_overall['lr']}, batch={best_overall['batch_size']}\")\n",
    "    print(f\"   â€¢ Overfitting gap: {best_overall['overfit_gap']:.4f}\")\n",
    "    \n",
    "    print(f\"\\nðŸŽ¯ Most Reliable (best generalization):\")\n",
    "    print(f\"   {least_overfit['experiment']}\")\n",
    "    print(f\"   â€¢ F1: {least_overfit['test_f1']:.4f} | Gap: {least_overfit['overfit_gap']:.4f}\")\n",
    "    print(f\"   â€¢ Config: {least_overfit['input_type']}, {least_overfit['hidden_dims']}\")\n",
    "    print(f\"   â€¢ Use when: You need consistent performance on unseen data\")\n",
    "    \n",
    "    print(f\"\\nðŸ” Best for Catching Deforestation (minimize false negatives):\")\n",
    "    print(f\"   {best_recall['experiment']}\")\n",
    "    print(f\"   â€¢ Recall: {best_recall['test_recall']:.4f} (catches {best_recall['test_recall']*100:.1f}% of deforestation)\")\n",
    "    print(f\"   â€¢ Precision: {best_recall['test_precision']:.4f} (FP rate: {best_recall['false_positive_rate']:.4f})\")\n",
    "    print(f\"   â€¢ Use when: Missing deforestation is more costly than false alarms\")\n",
    "    \n",
    "    print(f\"\\nâœ… Best for Reducing False Alarms (minimize false positives):\")\n",
    "    print(f\"   {best_precision['experiment']}\")\n",
    "    print(f\"   â€¢ Precision: {best_precision['test_precision']:.4f} ({best_precision['test_precision']*100:.1f}% of alerts are real)\")\n",
    "    print(f\"   â€¢ Recall: {best_precision['test_recall']:.4f} (FN rate: {best_precision['false_negative_rate']:.4f})\")\n",
    "    print(f\"   â€¢ Use when: False alarms are expensive or cause alert fatigue\")\n",
    "    \n",
    "    print(f\"\\nðŸ“Š Best Ranking Model (highest AUC):\")\n",
    "    print(f\"   {best_auc['experiment']}\")\n",
    "    print(f\"   â€¢ AUC: {best_auc['test_roc_auc']:.4f}\")\n",
    "    print(f\"   â€¢ Use when: You need to rank areas by deforestation likelihood\")\n",
    "    \n",
    "    print(f\"\\n{'='*120}\")\n",
    "    print(\"2. KEY INSIGHTS FROM EXPERIMENTS\")\n",
    "    print(f\"{'='*120}\")\n",
    "    \n",
    "    # Input type insights\n",
    "    print(f\"\\nðŸ“¥ Input Representation:\")\n",
    "    input_analysis = df.groupby('input_type').agg({\n",
    "        'test_f1': ['mean', 'max', 'count']\n",
    "    }).round(4)\n",
    "    for input_type in df['input_type'].unique():\n",
    "        stats = input_analysis.loc[input_type]\n",
    "        print(f\"   â€¢ {input_type}: mean F1={stats[('test_f1', 'mean')]:.4f}, \"\n",
    "              f\"max F1={stats[('test_f1', 'max')]:.4f} (n={int(stats[('test_f1', 'count')])})\")\n",
    "    \n",
    "    best_input = df.groupby('input_type')['test_f1'].mean().idxmax()\n",
    "    print(f\"   âžœ Winner: {best_input}\")\n",
    "    \n",
    "    # Regularization insights\n",
    "    print(f\"\\nðŸ›¡ï¸ Regularization:\")\n",
    "    avg_overfit = df['overfit_gap'].mean()\n",
    "    severe_overfit = (df['overfit_gap'] > 0.15).sum()\n",
    "    well_generalized = (df['overfit_gap'].abs() < 0.05).sum()\n",
    "    \n",
    "    print(f\"   â€¢ Average overfitting gap: {avg_overfit:.4f}\")\n",
    "    print(f\"   â€¢ Models with severe overfit (>0.15): {severe_overfit}/{len(df)}\")\n",
    "    print(f\"   â€¢ Well-generalized models (|gap|<0.05): {well_generalized}/{len(df)}\")\n",
    "    \n",
    "    if avg_overfit > 0.10:\n",
    "        print(f\"   âš ï¸  STRONG OVERFITTING DETECTED!\")\n",
    "        \n",
    "        # Find what helps\n",
    "        concat_df = df[df['input_type'] == 'concat']\n",
    "        if len(concat_df) > 5:\n",
    "            high_reg = concat_df[concat_df['dropout'] >= 0.5]\n",
    "            low_reg = concat_df[concat_df['dropout'] < 0.5]\n",
    "            if len(high_reg) > 0 and len(low_reg) > 0:\n",
    "                print(f\"   â€¢ High dropout (â‰¥0.5) gap: {high_reg['overfit_gap'].mean():.4f}\")\n",
    "                print(f\"   â€¢ Low dropout (<0.5) gap: {low_reg['overfit_gap'].mean():.4f}\")\n",
    "    \n",
    "    # Optimal hyperparameters\n",
    "    print(f\"\\nâš™ï¸ Optimal Hyperparameters (based on top 10 models):\")\n",
    "    top_10 = df.nlargest(10, 'test_f1')\n",
    "    \n",
    "    print(f\"   â€¢ Dropout: {top_10['dropout'].mode().values[0]} (mode), \"\n",
    "          f\"range: [{top_10['dropout'].min()}, {top_10['dropout'].max()}]\")\n",
    "    print(f\"   â€¢ Learning rate: {top_10['lr'].mode().values[0]} (mode), \"\n",
    "          f\"range: [{top_10['lr'].min()}, {top_10['lr'].max()}]\")\n",
    "    print(f\"   â€¢ Weight decay: {top_10['weight_decay'].mode().values[0]} (mode), \"\n",
    "          f\"range: [{top_10['weight_decay'].min()}, {top_10['weight_decay'].max()}]\")\n",
    "    print(f\"   â€¢ Batch size: {top_10['batch_size'].mode().values[0]} (mode)\")\n",
    "    \n",
    "    # Architecture insights\n",
    "    print(f\"\\nðŸ—ï¸ Architecture:\")\n",
    "    print(f\"   â€¢ Depth: {top_10['num_layers'].mode().values[0]} layers (mode), \"\n",
    "          f\"range: [{top_10['num_layers'].min()}, {top_10['num_layers'].max()}]\")\n",
    "    print(f\"   â€¢ Total size: {top_10['total_hidden_units'].mean():.0f} units (mean), \"\n",
    "          f\"range: [{top_10['total_hidden_units'].min()}, {top_10['total_hidden_units'].max()}]\")\n",
    "    \n",
    "    # Convergence insights\n",
    "    print(f\"\\nâ±ï¸ Training Dynamics:\")\n",
    "    print(f\"   â€¢ Average convergence: {df['best_epoch'].mean():.1f} epochs\")\n",
    "    print(f\"   â€¢ Fastest: {df['best_epoch'].min():.0f} epochs ({df.loc[df['best_epoch'].idxmin(), 'experiment']})\")\n",
    "    print(f\"   â€¢ Slowest: {df['best_epoch'].max():.0f} epochs\")\n",
    "    \n",
    "    print(f\"\\n{'='*120}\")\n",
    "    print(\"3. ACTIONABLE NEXT STEPS\")\n",
    "    print(f\"{'='*120}\")\n",
    "    \n",
    "    print(f\"\\nâœ… Implement immediately:\")\n",
    "    print(f\"   1. Use {best_overall['experiment']} for production\")\n",
    "    print(f\"   2. Set up ensemble with top 3-5 models for robustness\")\n",
    "    print(f\"   3. Use {best_recall['experiment']} if false negatives are critical\")\n",
    "    \n",
    "    print(f\"\\nðŸ”¬ Further experimentation:\")\n",
    "    \n",
    "    # Check what hasn't been explored enough\n",
    "    if df['input_type'].value_counts().get('combined', 0) < 5:\n",
    "        print(f\"   â€¢ Explore 'combined' input more (only {df['input_type'].value_counts().get('combined', 0)} experiments)\")\n",
    "    \n",
    "    if len(df[df['dropout'] > 0.6]) < 5:\n",
    "        print(f\"   â€¢ Test higher dropout (>0.6) to reduce overfitting\")\n",
    "    \n",
    "    if df['weight_decay'].nunique() < 5:\n",
    "        print(f\"   â€¢ Expand weight decay sweep\")\n",
    "    \n",
    "    if (df['overfit_gap'] > 0.10).sum() > len(df) * 0.5:\n",
    "        print(f\"   â€¢ Focus on regularization - majority of models overfit\")\n",
    "    \n",
    "    # Seed variance check\n",
    "    df['exp_base'] = df['experiment'].str.replace(r'_seed\\d+', '', regex=True)\n",
    "    replicated = df.groupby('exp_base').size()\n",
    "    if (replicated > 1).sum() < 3:\n",
    "        print(f\"   â€¢ Add more seed replicates for variance estimation\")\n",
    "    \n",
    "    print(f\"\\nðŸ“Š Model selection guide:\")\n",
    "    print(f\"   â€¢ Need maximum F1? â†’ {best_overall['experiment']}\")\n",
    "    print(f\"   â€¢ Need reliability? â†’ {least_overfit['experiment']}\")\n",
    "    print(f\"   â€¢ Need to catch everything? â†’ {best_recall['experiment']}\")\n",
    "    print(f\"   â€¢ Need to avoid false alarms? â†’ {best_precision['experiment']}\")\n",
    "    print(f\"   â€¢ Need probability ranking? â†’ {best_auc['experiment']}\")\n",
    "\n",
    "\n",
    "def export_results_csv(df, save_dir):\n",
    "    \"\"\"Export detailed results to CSV\"\"\"\n",
    "    output_file = save_dir / 'detailed_results.csv'\n",
    "    df.to_csv(output_file, index=False)\n",
    "    print(f\"\\nâœ… Detailed results exported to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2454368e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import rootutils\n",
    "from scipy import stats\n",
    "\n",
    "root_path = rootutils.find_root()\n",
    "\n",
    "def load_experiment_results(summary_file=None, folder_name=\"experiments_more\"):\n",
    "    \"\"\"Load experiment results from JSON file\"\"\"\n",
    "    experiments_dir = root_path / folder_name\n",
    "\n",
    "    if summary_file is None:\n",
    "        summary_files = sorted(experiments_dir.glob(\"summary_*.json\"))\n",
    "        if not summary_files:\n",
    "            raise FileNotFoundError(\"No summary files found in experiments directory\")\n",
    "        summary_file = summary_files[-1]\n",
    "        print(f\"Loading most recent summary: {summary_file.name}\")\n",
    "    else:\n",
    "        summary_file = Path(summary_file)\n",
    "    \n",
    "    with open(summary_file, 'r') as f:\n",
    "        results = json.load(f)\n",
    "    \n",
    "    return results, summary_file\n",
    "\n",
    "\n",
    "def results_to_dataframe(results):\n",
    "    \"\"\"Convert results list to pandas DataFrame with extended features\"\"\"\n",
    "    if not results:\n",
    "        raise ValueError(\"No results to analyze\")\n",
    "    \n",
    "    data = []\n",
    "    for result in results:\n",
    "        row = {\n",
    "            'experiment': result['experiment_name'],\n",
    "            'test_f1': result['test_f1'],\n",
    "            'test_precision': result['test_precision'],\n",
    "            'test_recall': result['test_recall'],\n",
    "            'test_auc': result['test_roc_auc'],\n",
    "            'val_f1': result['best_val_f1'],\n",
    "            'overfit_gap': result['overfit_gap'],\n",
    "            'best_epoch': result['best_epoch'],\n",
    "            'input_type': result['config']['input_type'],\n",
    "            'hidden_dims': str(result['config']['hidden_dims']),\n",
    "            'dropout': result['config']['dropout'],\n",
    "            'lr': result['config']['lr'],\n",
    "            'weight_decay': result['config']['weight_decay'],\n",
    "            'batch_size': result['config']['batch_size'],\n",
    "            'patience': result['config'].get('patience', 15),\n",
    "            'seed': result['config']['seed'],\n",
    "        }\n",
    "        \n",
    "        # Compute derived metrics\n",
    "        cm = np.array(result['confusion_matrix'])\n",
    "        row['tn'] = cm[0, 0]\n",
    "        row['fp'] = cm[0, 1]\n",
    "        row['fn'] = cm[1, 0]\n",
    "        row['tp'] = cm[1, 1]\n",
    "        row['false_positive_rate'] = row['fp'] / (row['fp'] + row['tn']) if (row['fp'] + row['tn']) > 0 else 0\n",
    "        row['false_negative_rate'] = row['fn'] / (row['fn'] + row['tp']) if (row['fn'] + row['tp']) > 0 else 0\n",
    "        \n",
    "        # Model complexity - handle both list and string formats\n",
    "        hidden_dims_raw = result['config']['hidden_dims']\n",
    "        if isinstance(hidden_dims_raw, str):\n",
    "            hidden_list = eval(hidden_dims_raw)\n",
    "        else:\n",
    "            hidden_list = hidden_dims_raw\n",
    "        \n",
    "        row['num_layers'] = len(hidden_list)\n",
    "        row['total_hidden_units'] = sum(hidden_list)\n",
    "        row['max_layer_size'] = max(hidden_list)\n",
    "        \n",
    "        data.append(row)\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "\n",
    "def print_summary_table(df, top_n=20):\n",
    "    \"\"\"Print formatted summary table\"\"\"\n",
    "    print(\"\\n\" + \"=\"*120)\n",
    "    print(\"EXPERIMENT RESULTS SUMMARY\")\n",
    "    print(\"=\"*120)\n",
    "    \n",
    "    df_sorted = df.sort_values('test_f1', ascending=False)\n",
    "    \n",
    "    print(f\"\\n{'Rank':<6}{'Experiment':<35}{'F1':<8}{'Prec':<8}{'Recall':<8}{'AUC':<8}{'Overfit':<10}{'Epoch':<7}\")\n",
    "    print(\"-\"*120)\n",
    "    \n",
    "    for idx, (_, row) in enumerate(df_sorted.head(top_n).iterrows(), 1):\n",
    "        print(f\"{idx:<6}{row['experiment']:<35}{row['test_f1']:<8.4f}{row['test_precision']:<8.4f}\"\n",
    "              f\"{row['test_recall']:<8.4f}{row['test_auc']:<8.4f}{row['overfit_gap']:<10.4f}{row['best_epoch']:<7.0f}\")\n",
    "    \n",
    "    # Print bottom performers too\n",
    "    if len(df_sorted) > 5:\n",
    "        print(\"\\n\" + \"-\"*120)\n",
    "        print(\"BOTTOM 5 PERFORMERS:\")\n",
    "        print(\"-\"*120)\n",
    "        for idx, (_, row) in enumerate(df_sorted.tail(5).iterrows(), len(df_sorted)-4):\n",
    "            print(f\"{idx:<6}{row['experiment']:<35}{row['test_f1']:<8.4f}{row['test_precision']:<8.4f}\"\n",
    "                  f\"{row['test_recall']:<8.4f}{row['test_auc']:<8.4f}{row['overfit_gap']:<10.4f}{row['best_epoch']:<7.0f}\")\n",
    "    \n",
    "    # Best by different metrics\n",
    "    print(f\"\\n\" + \"=\"*120)\n",
    "    print(\"BEST MODELS BY METRIC\")\n",
    "    print(\"=\"*120)\n",
    "    \n",
    "    metrics = {\n",
    "        'F1 Score': ('test_f1', 'max'),\n",
    "        'Precision': ('test_precision', 'max'),\n",
    "        'Recall': ('test_recall', 'max'),\n",
    "        'AUC': ('test_auc', 'max'),\n",
    "        'Least Overfit': ('overfit_gap', 'min'),\n",
    "        'Fastest Convergence': ('best_epoch', 'min'),\n",
    "        'Best Val-Test Agreement': ('overfit_gap', 'abs_min'),\n",
    "    }\n",
    "    \n",
    "    for metric_name, (col, agg) in metrics.items():\n",
    "        if agg == 'abs_min':\n",
    "            idx = df[col].abs().idxmin()\n",
    "        else:\n",
    "            idx = df[col].idxmax() if agg == 'max' else df[col].idxmin()\n",
    "        row = df.loc[idx]\n",
    "        print(f\"\\n{metric_name}:\")\n",
    "        print(f\"  Model: {row['experiment']}\")\n",
    "        print(f\"  Value: {row[col]:.4f}\")\n",
    "        print(f\"  Config: input={row['input_type']}, arch={row['hidden_dims']}, \"\n",
    "              f\"dropout={row['dropout']}, lr={row['lr']}, wd={row['weight_decay']}\")\n",
    "\n",
    "\n",
    "def analyze_by_category(df):\n",
    "    \"\"\"Analyze results by different configuration categories\"\"\"\n",
    "    print(f\"\\n\" + \"=\"*120)\n",
    "    print(\"DETAILED ANALYSIS BY CONFIGURATION\")\n",
    "    print(\"=\"*120)\n",
    "    \n",
    "    # Helper function for pretty printing\n",
    "    def print_analysis(group_col, title):\n",
    "        print(f\"\\n{title}:\")\n",
    "        print(\"-\"*120)\n",
    "        \n",
    "        if group_col not in df.columns or df[group_col].isna().all():\n",
    "            print(\"  No data available for this category\")\n",
    "            return\n",
    "            \n",
    "        analysis = df.groupby(group_col).agg({\n",
    "            'test_f1': ['count', 'mean', 'std', 'min', 'max'],\n",
    "            'overfit_gap': ['mean', 'std'],\n",
    "            'test_precision': 'mean',\n",
    "            'test_recall': 'mean',\n",
    "            'test_auc': 'mean',\n",
    "            'best_epoch': 'mean'\n",
    "        }).round(4)\n",
    "        print(analysis)\n",
    "        \n",
    "        # Statistical test if enough groups\n",
    "        if len(df[group_col].unique()) >= 2:\n",
    "            groups = [group['test_f1'].values for name, group in df.groupby(group_col) if len(group) >= 2]\n",
    "            if len(groups) >= 2:\n",
    "                try:\n",
    "                    statistic, pvalue = stats.f_oneway(*groups)\n",
    "                    print(f\"\\nANOVA F-statistic: {statistic:.4f}, p-value: {pvalue:.4e}\")\n",
    "                    if pvalue < 0.05:\n",
    "                        print(\"  â†’ Statistically significant differences detected!\")\n",
    "                    else:\n",
    "                        print(\"  â†’ No significant differences (might just be noise)\")\n",
    "                except:\n",
    "                    pass\n",
    "    \n",
    "    # Run analyses\n",
    "    print_analysis('input_type', '1. BY INPUT TYPE')\n",
    "    print_analysis('dropout', '2. BY DROPOUT RATE')\n",
    "    print_analysis('lr', '3. BY LEARNING RATE')\n",
    "    print_analysis('weight_decay', '4. BY WEIGHT DECAY')\n",
    "    print_analysis('batch_size', '5. BY BATCH SIZE')\n",
    "    print_analysis('num_layers', '6. BY NETWORK DEPTH')\n",
    "    \n",
    "    if 'patience' in df.columns and df['patience'].nunique() > 1:\n",
    "        print_analysis('patience', '7. BY EARLY STOPPING PATIENCE')\n",
    "    \n",
    "    # Architecture size bins\n",
    "    df['arch_size'] = pd.cut(df['total_hidden_units'], \n",
    "                              bins=[0, 300, 600, 900, 1500, 5000],\n",
    "                              labels=['tiny', 'small', 'medium', 'large', 'huge'])\n",
    "    print_analysis('arch_size', '8. BY ARCHITECTURE SIZE')\n",
    "\n",
    "\n",
    "def deep_dive_concat(df):\n",
    "    \"\"\"Deep analysis specifically for concat experiments\"\"\"\n",
    "    print(f\"\\n\" + \"=\"*120)\n",
    "    print(\"DEEP DIVE: CONCAT INPUT EXPERIMENTS\")\n",
    "    print(\"=\"*120)\n",
    "    \n",
    "    concat_df = df[df['input_type'] == 'concat'].copy()\n",
    "    \n",
    "    if len(concat_df) == 0:\n",
    "        print(\"No concat experiments found!\")\n",
    "        return\n",
    "    \n",
    "    print(f\"\\nTotal concat experiments: {len(concat_df)}\")\n",
    "    print(f\"Best F1: {concat_df['test_f1'].max():.4f}\")\n",
    "    print(f\"Worst F1: {concat_df['test_f1'].min():.4f}\")\n",
    "    print(f\"Mean F1: {concat_df['test_f1'].mean():.4f} Â± {concat_df['test_f1'].std():.4f}\")\n",
    "    print(f\"Median overfit gap: {concat_df['overfit_gap'].median():.4f}\")\n",
    "    \n",
    "    # Find optimal hyperparameters\n",
    "    print(\"\\n\" + \"-\"*120)\n",
    "    print(\"OPTIMAL HYPERPARAMETERS FOR CONCAT:\")\n",
    "    print(\"-\"*120)\n",
    "    \n",
    "    for param in ['dropout', 'lr', 'weight_decay', 'batch_size', 'hidden_dims']:\n",
    "        best_idx = concat_df['test_f1'].idxmax()\n",
    "        top_5 = concat_df.nlargest(min(5, len(concat_df)), 'test_f1')\n",
    "        \n",
    "        print(f\"\\n{param.upper()}:\")\n",
    "        print(f\"  Best single model: {concat_df.loc[best_idx, param]}\")\n",
    "        \n",
    "        if param == 'hidden_dims':\n",
    "            print(f\"  Most common in top {len(top_5)}: {top_5[param].mode().values[0] if len(top_5[param].mode()) > 0 else 'N/A'}\")\n",
    "        else:\n",
    "            print(f\"  Top {len(top_5)} average: {top_5[param].mean():.6f}\")\n",
    "        \n",
    "        # Show distribution\n",
    "        if param != 'hidden_dims' and len(top_5) > 0:\n",
    "            value_counts = top_5[param].value_counts()\n",
    "            print(f\"  Distribution in top {len(top_5)}:\")\n",
    "            for val, count in value_counts.head(3).items():\n",
    "                print(f\"    {val}: {count}/{len(top_5)}\")\n",
    "    \n",
    "    # Correlation analysis\n",
    "    print(\"\\n\" + \"-\"*120)\n",
    "    print(\"HYPERPARAMETER CORRELATIONS WITH F1:\")\n",
    "    print(\"-\"*120)\n",
    "    \n",
    "    numeric_params = ['dropout', 'lr', 'weight_decay', 'batch_size', 'total_hidden_units', 'num_layers']\n",
    "    correlations = {}\n",
    "    \n",
    "    for param in numeric_params:\n",
    "        if param in concat_df.columns and concat_df[param].nunique() > 1:\n",
    "            corr = concat_df[param].corr(concat_df['test_f1'])\n",
    "            correlations[param] = corr\n",
    "            print(f\"{param:>20}: {corr:>7.4f}\")\n",
    "    \n",
    "    # Find sweet spots\n",
    "    print(\"\\n\" + \"-\"*120)\n",
    "    print(\"SWEET SPOT RANGES (values where F1 > median):\")\n",
    "    print(\"-\"*120)\n",
    "    \n",
    "    median_f1 = concat_df['test_f1'].median()\n",
    "    high_performers = concat_df[concat_df['test_f1'] > median_f1]\n",
    "    \n",
    "    if len(high_performers) > 0:\n",
    "        for param in ['dropout', 'lr', 'weight_decay']:\n",
    "            if high_performers[param].nunique() > 1:\n",
    "                print(f\"{param}: [{high_performers[param].min():.6f}, {high_performers[param].max():.6f}]\")\n",
    "    else:\n",
    "        print(\"No high performers found\")\n",
    "\n",
    "\n",
    "def analyze_regularization_tradeoffs(df):\n",
    "    \"\"\"Analyze the relationship between regularization and performance\"\"\"\n",
    "    print(f\"\\n\" + \"=\"*120)\n",
    "    print(\"REGULARIZATION ANALYSIS\")\n",
    "    print(\"=\"*120)\n",
    "    \n",
    "    # Define regularization strength\n",
    "    df['reg_strength'] = df['dropout'] + np.log10(df['weight_decay'] + 1e-10) / 5\n",
    "    \n",
    "    # Bin into categories\n",
    "    df['reg_category'] = pd.cut(df['reg_strength'], \n",
    "                                 bins=[-np.inf, -1, 0, 1, np.inf],\n",
    "                                 labels=['minimal', 'light', 'moderate', 'heavy'])\n",
    "    \n",
    "    print(\"\\nPerformance by regularization strength:\")\n",
    "    try:\n",
    "        reg_analysis = df.groupby('reg_category').agg({\n",
    "            'test_f1': ['count', 'mean', 'std', 'max'],\n",
    "            'overfit_gap': ['mean', 'std'],\n",
    "            'test_precision': 'mean',\n",
    "            'test_recall': 'mean',\n",
    "        }).round(4)\n",
    "        print(reg_analysis)\n",
    "    except Exception as e:\n",
    "        print(f\"  Could not compute regularization analysis: {e}\")\n",
    "    \n",
    "    # Overfitting analysis\n",
    "    print(\"\\n\" + \"-\"*120)\n",
    "    print(\"OVERFITTING STATISTICS:\")\n",
    "    print(\"-\"*120)\n",
    "    print(f\"Models with overfit_gap > 0.15: {(df['overfit_gap'] > 0.15).sum()}/{len(df)}\")\n",
    "    print(f\"Models with overfit_gap < 0.05: {(df['overfit_gap'] < 0.05).sum()}/{len(df)}\")\n",
    "    print(f\"Models with negative gap (test > train): {(df['overfit_gap'] < 0).sum()}/{len(df)}\")\n",
    "    \n",
    "    # Best regularization strategy\n",
    "    well_generalized = df[df['overfit_gap'].abs() < 0.10]\n",
    "    if len(well_generalized) > 0:\n",
    "        best_generalized = well_generalized.loc[well_generalized['test_f1'].idxmax()]\n",
    "        print(f\"\\nBest well-generalized model (|gap| < 0.10):\")\n",
    "        print(f\"  {best_generalized['experiment']}\")\n",
    "        print(f\"  F1: {best_generalized['test_f1']:.4f}, Gap: {best_generalized['overfit_gap']:.4f}\")\n",
    "        print(f\"  Config: dropout={best_generalized['dropout']}, wd={best_generalized['weight_decay']}\")\n",
    "\n",
    "\n",
    "def analyze_precision_recall_tradeoff(df):\n",
    "    \"\"\"Analyze precision-recall tradeoff and identify Pareto frontier\"\"\"\n",
    "    print(f\"\\n\" + \"=\"*120)\n",
    "    print(\"PRECISION-RECALL TRADEOFF ANALYSIS\")\n",
    "    print(\"=\"*120)\n",
    "    \n",
    "    # Sort by F1 and show precision-recall balance\n",
    "    print(\"\\nTop 10 models by F1 with precision-recall breakdown:\")\n",
    "    print(\"-\"*120)\n",
    "    top_10 = df.nlargest(min(10, len(df)), 'test_f1')\n",
    "    \n",
    "    for idx, (_, row) in enumerate(top_10.iterrows(), 1):\n",
    "        prec_rec_diff = abs(row['test_precision'] - row['test_recall'])\n",
    "        balance = \"balanced\" if prec_rec_diff < 0.05 else (\"precision-biased\" if row['test_precision'] > row['test_recall'] else \"recall-biased\")\n",
    "        print(f\"{idx:>2}. {row['experiment']:<35} F1:{row['test_f1']:.4f}  \"\n",
    "              f\"P:{row['test_precision']:.4f}  R:{row['test_recall']:.4f}  [{balance}]\")\n",
    "    \n",
    "    # Identify Pareto-optimal models\n",
    "    print(\"\\n\" + \"-\"*120)\n",
    "    print(\"PARETO FRONTIER (models where you can't improve one metric without hurting the other):\")\n",
    "    print(\"-\"*120)\n",
    "    \n",
    "    pareto_models = []\n",
    "    for idx, row in df.iterrows():\n",
    "        is_pareto = True\n",
    "        for _, other in df.iterrows():\n",
    "            if (other['test_precision'] >= row['test_precision'] and \n",
    "                other['test_recall'] >= row['test_recall'] and\n",
    "                (other['test_precision'] > row['test_precision'] or other['test_recall'] > row['test_recall'])):\n",
    "                is_pareto = False\n",
    "                break\n",
    "        if is_pareto:\n",
    "            pareto_models.append(row)\n",
    "    \n",
    "    pareto_df = pd.DataFrame(pareto_models).sort_values('test_f1', ascending=False)\n",
    "    print(f\"\\nFound {len(pareto_df)} Pareto-optimal models:\")\n",
    "    for _, row in pareto_df.head(10).iterrows():\n",
    "        print(f\"  {row['experiment']:<35} P:{row['test_precision']:.4f}  R:{row['test_recall']:.4f}  F1:{row['test_f1']:.4f}\")\n",
    "\n",
    "\n",
    "def analyze_seed_variance(df):\n",
    "    \"\"\"Analyze variance across different random seeds\"\"\"\n",
    "    print(f\"\\n\" + \"=\"*120)\n",
    "    print(\"RANDOM SEED VARIANCE ANALYSIS\")\n",
    "    print(\"=\"*120)\n",
    "    \n",
    "    # Find experiments with multiple seeds\n",
    "    df['exp_base'] = df['experiment'].str.replace(r'_seed\\d+', '', regex=True)\n",
    "    seed_groups = df.groupby('exp_base').filter(lambda x: len(x) > 1)\n",
    "    \n",
    "    if len(seed_groups) == 0:\n",
    "        print(\"\\nNo replicated experiments found (need same config with different seeds)\")\n",
    "        return\n",
    "    \n",
    "    print(f\"\\nFound {seed_groups['exp_base'].nunique()} configurations with multiple seeds:\")\n",
    "    print(\"-\"*120)\n",
    "    \n",
    "    for exp_base, group in seed_groups.groupby('exp_base'):\n",
    "        print(f\"\\n{exp_base}:\")\n",
    "        print(f\"  Runs: {len(group)}\")\n",
    "        print(f\"  F1: {group['test_f1'].mean():.4f} Â± {group['test_f1'].std():.4f} \"\n",
    "              f\"(range: [{group['test_f1'].min():.4f}, {group['test_f1'].max():.4f}])\")\n",
    "        print(f\"  Precision: {group['test_precision'].mean():.4f} Â± {group['test_precision'].std():.4f}\")\n",
    "        print(f\"  Recall: {group['test_recall'].mean():.4f} Â± {group['test_recall'].std():.4f}\")\n",
    "        print(f\"  Overfit gap: {group['overfit_gap'].mean():.4f} Â± {group['overfit_gap'].std():.4f}\")\n",
    "        \n",
    "        if group['test_f1'].std() > 0.02:\n",
    "            print(f\"  âš ï¸  High variance detected! Results may be unstable.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4075c7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def export_results_csv(df, save_dir):\n",
    "    \"\"\"Export detailed results to CSV\"\"\"\n",
    "    output_file = save_dir / 'detailed_results.csv'\n",
    "    df.to_csv(output_file, index=False)\n",
    "    print(f\"\\nâœ… Detailed results exported to {output_file}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "34629721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading most recent summary: summary_20250929_184544.json\n",
      "\n",
      "========================================================================================================================\n",
      "EXPERIMENT RESULTS SUMMARY\n",
      "========================================================================================================================\n",
      "\n",
      "Rank  Experiment                         F1      Prec    Recall  AUC     Overfit   Epoch  \n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "1     concat_minimal_compression         0.8232  0.7670  0.8882  0.8824  0.1260    55     \n",
      "2     concat_very_wide                   0.8173  0.7719  0.8684  0.8856  0.1105    43     \n",
      "3     concat_wide_v2                     0.8162  0.7751  0.8618  0.8837  0.1352    49     \n",
      "4     concat_wide_v1                     0.8050  0.7711  0.8421  0.8827  0.0904    20     \n",
      "\n",
      "========================================================================================================================\n",
      "BEST MODELS BY METRIC\n",
      "========================================================================================================================\n",
      "\n",
      "F1 Score:\n",
      "  Model: concat_minimal_compression\n",
      "  Value: 0.8232\n",
      "  Config: input=concat, arch=[1400, 700, 350], dropout=0.4, lr=0.001, wd=0.0001\n",
      "\n",
      "Precision:\n",
      "  Model: concat_wide_v2\n",
      "  Value: 0.7751\n",
      "  Config: input=concat, arch=[1280, 640, 320], dropout=0.4, lr=0.001, wd=0.0001\n",
      "\n",
      "Recall:\n",
      "  Model: concat_minimal_compression\n",
      "  Value: 0.8882\n",
      "  Config: input=concat, arch=[1400, 700, 350], dropout=0.4, lr=0.001, wd=0.0001\n",
      "\n",
      "AUC:\n",
      "  Model: concat_very_wide\n",
      "  Value: 0.8856\n",
      "  Config: input=concat, arch=[1536, 768, 384], dropout=0.4, lr=0.001, wd=0.0001\n",
      "\n",
      "Least Overfit:\n",
      "  Model: concat_wide_v1\n",
      "  Value: 0.0904\n",
      "  Config: input=concat, arch=[1024, 512, 256], dropout=0.4, lr=0.001, wd=0.0001\n",
      "\n",
      "Fastest Convergence:\n",
      "  Model: concat_wide_v1\n",
      "  Value: 20.0000\n",
      "  Config: input=concat, arch=[1024, 512, 256], dropout=0.4, lr=0.001, wd=0.0001\n",
      "\n",
      "Best Val-Test Agreement:\n",
      "  Model: concat_wide_v1\n",
      "  Value: 0.0904\n",
      "  Config: input=concat, arch=[1024, 512, 256], dropout=0.4, lr=0.001, wd=0.0001\n",
      "\n",
      "========================================================================================================================\n",
      "DETAILED ANALYSIS BY CONFIGURATION\n",
      "========================================================================================================================\n",
      "\n",
      "1. BY INPUT TYPE:\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "           test_f1                                overfit_gap          \\\n",
      "             count    mean     std    min     max        mean     std   \n",
      "input_type                                                              \n",
      "concat           4  0.8154  0.0076  0.805  0.8232      0.1155  0.0196   \n",
      "\n",
      "           test_precision test_recall test_auc best_epoch  \n",
      "                     mean        mean     mean       mean  \n",
      "input_type                                                 \n",
      "concat             0.7713      0.8651   0.8836      41.75  \n",
      "\n",
      "2. BY DROPOUT RATE:\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "        test_f1                                overfit_gap          \\\n",
      "          count    mean     std    min     max        mean     std   \n",
      "dropout                                                              \n",
      "0.4           4  0.8154  0.0076  0.805  0.8232      0.1155  0.0196   \n",
      "\n",
      "        test_precision test_recall test_auc best_epoch  \n",
      "                  mean        mean     mean       mean  \n",
      "dropout                                                 \n",
      "0.4             0.7713      0.8651   0.8836      41.75  \n",
      "\n",
      "3. BY LEARNING RATE:\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "      test_f1                                overfit_gap          \\\n",
      "        count    mean     std    min     max        mean     std   \n",
      "lr                                                                 \n",
      "0.001       4  0.8154  0.0076  0.805  0.8232      0.1155  0.0196   \n",
      "\n",
      "      test_precision test_recall test_auc best_epoch  \n",
      "                mean        mean     mean       mean  \n",
      "lr                                                    \n",
      "0.001         0.7713      0.8651   0.8836      41.75  \n",
      "\n",
      "4. BY WEIGHT DECAY:\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "             test_f1                                overfit_gap          \\\n",
      "               count    mean     std    min     max        mean     std   \n",
      "weight_decay                                                              \n",
      "0.0001             4  0.8154  0.0076  0.805  0.8232      0.1155  0.0196   \n",
      "\n",
      "             test_precision test_recall test_auc best_epoch  \n",
      "                       mean        mean     mean       mean  \n",
      "weight_decay                                                 \n",
      "0.0001               0.7713      0.8651   0.8836      41.75  \n",
      "\n",
      "5. BY BATCH SIZE:\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "           test_f1                                overfit_gap          \\\n",
      "             count    mean     std    min     max        mean     std   \n",
      "batch_size                                                              \n",
      "64               4  0.8154  0.0076  0.805  0.8232      0.1155  0.0196   \n",
      "\n",
      "           test_precision test_recall test_auc best_epoch  \n",
      "                     mean        mean     mean       mean  \n",
      "batch_size                                                 \n",
      "64                 0.7713      0.8651   0.8836      41.75  \n",
      "\n",
      "6. BY NETWORK DEPTH:\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "           test_f1                                overfit_gap          \\\n",
      "             count    mean     std    min     max        mean     std   \n",
      "num_layers                                                              \n",
      "3                4  0.8154  0.0076  0.805  0.8232      0.1155  0.0196   \n",
      "\n",
      "           test_precision test_recall test_auc best_epoch  \n",
      "                     mean        mean     mean       mean  \n",
      "num_layers                                                 \n",
      "3                  0.7713      0.8651   0.8836      41.75  \n",
      "\n",
      "8. BY ARCHITECTURE SIZE:\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "          test_f1                                overfit_gap          \\\n",
      "            count    mean     std    min     max        mean     std   \n",
      "arch_size                                                              \n",
      "tiny            0     NaN     NaN    NaN     NaN         NaN     NaN   \n",
      "small           0     NaN     NaN    NaN     NaN         NaN     NaN   \n",
      "medium          0     NaN     NaN    NaN     NaN         NaN     NaN   \n",
      "large           0     NaN     NaN    NaN     NaN         NaN     NaN   \n",
      "huge            4  0.8154  0.0076  0.805  0.8232      0.1155  0.0196   \n",
      "\n",
      "          test_precision test_recall test_auc best_epoch  \n",
      "                    mean        mean     mean       mean  \n",
      "arch_size                                                 \n",
      "tiny                 NaN         NaN      NaN        NaN  \n",
      "small                NaN         NaN      NaN        NaN  \n",
      "medium               NaN         NaN      NaN        NaN  \n",
      "large                NaN         NaN      NaN        NaN  \n",
      "huge              0.7713      0.8651   0.8836      41.75  \n",
      "\n",
      "========================================================================================================================\n",
      "DEEP DIVE: CONCAT INPUT EXPERIMENTS\n",
      "========================================================================================================================\n",
      "\n",
      "Total concat experiments: 4\n",
      "Best F1: 0.8232\n",
      "Worst F1: 0.8050\n",
      "Mean F1: 0.8154 Â± 0.0076\n",
      "Median overfit gap: 0.1183\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "OPTIMAL HYPERPARAMETERS FOR CONCAT:\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "DROPOUT:\n",
      "  Best single model: 0.4\n",
      "  Top 4 average: 0.400000\n",
      "  Distribution in top 4:\n",
      "    0.4: 4/4\n",
      "\n",
      "LR:\n",
      "  Best single model: 0.001\n",
      "  Top 4 average: 0.001000\n",
      "  Distribution in top 4:\n",
      "    0.001: 4/4\n",
      "\n",
      "WEIGHT_DECAY:\n",
      "  Best single model: 0.0001\n",
      "  Top 4 average: 0.000100\n",
      "  Distribution in top 4:\n",
      "    0.0001: 4/4\n",
      "\n",
      "BATCH_SIZE:\n",
      "  Best single model: 64\n",
      "  Top 4 average: 64.000000\n",
      "  Distribution in top 4:\n",
      "    64: 4/4\n",
      "\n",
      "HIDDEN_DIMS:\n",
      "  Best single model: [1400, 700, 350]\n",
      "  Most common in top 4: [1024, 512, 256]\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "HYPERPARAMETER CORRELATIONS WITH F1:\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "  total_hidden_units:  0.8250\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "SWEET SPOT RANGES (values where F1 > median):\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "========================================================================================================================\n",
      "REGULARIZATION ANALYSIS\n",
      "========================================================================================================================\n",
      "\n",
      "Performance by regularization strength:\n",
      "             test_f1                         overfit_gap          \\\n",
      "               count    mean     std     max        mean     std   \n",
      "reg_category                                                       \n",
      "minimal            0     NaN     NaN     NaN         NaN     NaN   \n",
      "light              4  0.8154  0.0076  0.8232      0.1155  0.0196   \n",
      "moderate           0     NaN     NaN     NaN         NaN     NaN   \n",
      "heavy              0     NaN     NaN     NaN         NaN     NaN   \n",
      "\n",
      "             test_precision test_recall  \n",
      "                       mean        mean  \n",
      "reg_category                             \n",
      "minimal                 NaN         NaN  \n",
      "light                0.7713      0.8651  \n",
      "moderate                NaN         NaN  \n",
      "heavy                   NaN         NaN  \n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "OVERFITTING STATISTICS:\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Models with overfit_gap > 0.15: 0/4\n",
      "Models with overfit_gap < 0.05: 0/4\n",
      "Models with negative gap (test > train): 0/4\n",
      "\n",
      "Best well-generalized model (|gap| < 0.10):\n",
      "  concat_wide_v1\n",
      "  F1: 0.8050, Gap: 0.0904\n",
      "  Config: dropout=0.4, wd=0.0001\n",
      "\n",
      "========================================================================================================================\n",
      "PRECISION-RECALL TRADEOFF ANALYSIS\n",
      "========================================================================================================================\n",
      "\n",
      "Top 10 models by F1 with precision-recall breakdown:\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      " 1. concat_minimal_compression          F1:0.8232  P:0.7670  R:0.8882  [recall-biased]\n",
      " 2. concat_very_wide                    F1:0.8173  P:0.7719  R:0.8684  [recall-biased]\n",
      " 3. concat_wide_v2                      F1:0.8162  P:0.7751  R:0.8618  [recall-biased]\n",
      " 4. concat_wide_v1                      F1:0.8050  P:0.7711  R:0.8421  [recall-biased]\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "PARETO FRONTIER (models where you can't improve one metric without hurting the other):\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Found 3 Pareto-optimal models:\n",
      "  concat_minimal_compression          P:0.7670  R:0.8882  F1:0.8232\n",
      "  concat_very_wide                    P:0.7719  R:0.8684  F1:0.8173\n",
      "  concat_wide_v2                      P:0.7751  R:0.8618  F1:0.8162\n",
      "\n",
      "========================================================================================================================\n",
      "RANDOM SEED VARIANCE ANALYSIS\n",
      "========================================================================================================================\n",
      "\n",
      "No replicated experiments found (need same config with different seeds)\n",
      "\n",
      "âœ… Detailed results exported to /net/home/lmaecker/own_projects/burned_embedder/experiments/detailed_results.csv\n",
      "\n",
      "========================================================================================================================\n",
      "âœ… ANALYSIS COMPLETE!\n",
      "========================================================================================================================\n",
      "\n",
      "Results saved to: /net/home/lmaecker/own_projects/burned_embedder/experiments\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2058201/2959291509.py:150: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  analysis = df.groupby(group_col).agg({\n",
      "/tmp/ipykernel_2058201/2959291509.py:280: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  reg_analysis = df.groupby('reg_category').agg({\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def main():\n",
    "    \"\"\"Main analysis function\"\"\"\n",
    "    results, summary_file = load_experiment_results(folder_name=\"experiments\")\n",
    "    \n",
    "    if not results:\n",
    "        print(\"No experiment results found!\")\n",
    "        return\n",
    "    \n",
    "    df = results_to_dataframe(results)\n",
    "    save_dir = root_path / \"experiments\"\n",
    "    \n",
    "    # Run text analyses\n",
    "    print_summary_table(df, top_n=20)\n",
    "    analyze_by_category(df)\n",
    "    deep_dive_concat(df)\n",
    "    analyze_regularization_tradeoffs(df)\n",
    "    analyze_precision_recall_tradeoff(df)\n",
    "    analyze_seed_variance(df)\n",
    "    \n",
    "    # Export to CSV\n",
    "    export_results_csv(df, save_dir)\n",
    "    \n",
    "    print(f\"\\n{'='*120}\")\n",
    "    print(\"âœ… ANALYSIS COMPLETE!\")\n",
    "    print(f\"{'='*120}\")\n",
    "    print(f\"\\nResults saved to: {save_dir}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8f3c65d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading most recent summary: summary_20250929_191713.json\n",
      "\n",
      "========================================================================================================================\n",
      "EXPERIMENT RESULTS SUMMARY\n",
      "========================================================================================================================\n",
      "\n",
      "Rank  Experiment                         F1      Prec    Recall  AUC     Overfit   Epoch  \n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "1     concat_best_seed2                  0.8740  0.8464  0.9035  0.9310  0.0398    63     \n",
      "2     concat_minimal_compression         0.8717  0.8393  0.9068  0.9201  0.0958    53     \n",
      "3     concat_wide_v2                     0.8689  0.8261  0.9164  0.9188  0.0926    47     \n",
      "4     concat_batch_32                    0.8674  0.8424  0.8939  0.9184  0.1018    52     \n",
      "5     concat_ablate_wider                0.8673  0.8338  0.9035  0.9194  0.0950    51     \n",
      "6     concat_best_seed4                  0.8661  0.8488  0.8842  0.9328  0.0539    50     \n",
      "7     concat_extra_large                 0.8645  0.8130  0.9228  0.9215  0.0916    37     \n",
      "8     combined_large                     0.8632  0.8107  0.9228  0.9177  0.1198    32     \n",
      "9     combined_regularized               0.8621  0.8410  0.8842  0.9225  0.1045    52     \n",
      "10    concat_lr_5e3                      0.8620  0.8240  0.9035  0.9187  0.0893    41     \n",
      "11    concat_ablate_no_dropout           0.8618  0.8011  0.9325  0.9160  0.1121    41     \n",
      "12    combined_baseline                  0.8615  0.8260  0.9003  0.9153  0.1282    44     \n",
      "13    combined_small                     0.8608  0.8567  0.8650  0.9167  0.0851    35     \n",
      "14    concat_wide_v1                     0.8606  0.8216  0.9035  0.9164  0.0782    30     \n",
      "15    concat_very_deep                   0.8606  0.8062  0.9228  0.9165  0.0797    31     \n",
      "16    concat_high_recall                 0.8585  0.8230  0.8971  0.9172  0.0847    22     \n",
      "17    concat_lr_5e4                      0.8576  0.8269  0.8907  0.9142  0.0858    56     \n",
      "18    concat_patience_25                 0.8523  0.8253  0.8810  0.9115  0.0798    30     \n",
      "19    concat_patience_30                 0.8523  0.8253  0.8810  0.9115  0.0798    30     \n",
      "20    concat_wd_5e4                      0.8520  0.8034  0.9068  0.9080  0.0546    25     \n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "BOTTOM 5 PERFORMERS:\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "51    concat_dropout_07                  0.7413  0.6333  0.8939  0.7598  0.1041    1      \n",
      "52    concat_ultra_optimized_v1          0.7406  0.6339  0.8907  0.7678  0.1117    1      \n",
      "53    concat_heavy_reg_v2                0.7397  0.6324  0.8907  0.7658  0.1038    1      \n",
      "54    diff_minimal_overfit               0.7143  0.6148  0.8521  0.7685  0.0636    5      \n",
      "55    diff_optimized_v2                  0.7121  0.6371  0.8071  0.7600  0.0957    2      \n",
      "\n",
      "========================================================================================================================\n",
      "BEST MODELS BY METRIC\n",
      "========================================================================================================================\n",
      "\n",
      "F1 Score:\n",
      "  Model: concat_best_seed2\n",
      "  Value: 0.8740\n",
      "  Config: input=concat, arch=[512, 256, 128], dropout=0.5, lr=0.0005, wd=0.0001\n",
      "\n",
      "Precision:\n",
      "  Model: concat_best_seed3\n",
      "  Value: 0.8789\n",
      "  Config: input=concat, arch=[512, 256, 128], dropout=0.5, lr=0.0005, wd=0.0001\n",
      "\n",
      "Recall:\n",
      "  Model: concat_ablate_no_dropout\n",
      "  Value: 0.9325\n",
      "  Config: input=concat, arch=[512, 256, 128], dropout=0.0, lr=0.001, wd=0.0\n",
      "\n",
      "AUC:\n",
      "  Model: concat_best_seed4\n",
      "  Value: 0.9328\n",
      "  Config: input=concat, arch=[512, 256, 128], dropout=0.5, lr=0.0005, wd=0.0001\n",
      "\n",
      "Least Overfit:\n",
      "  Model: concat_high_precision\n",
      "  Value: 0.0270\n",
      "  Config: input=concat, arch=[768, 384, 192], dropout=0.7, lr=5e-05, wd=0.0005\n",
      "\n",
      "Fastest Convergence:\n",
      "  Model: concat_tiny\n",
      "  Value: 1.0000\n",
      "  Config: input=concat, arch=[256], dropout=0.4, lr=0.001, wd=0.0\n",
      "\n",
      "Best Val-Test Agreement:\n",
      "  Model: concat_high_precision\n",
      "  Value: 0.0270\n",
      "  Config: input=concat, arch=[768, 384, 192], dropout=0.7, lr=5e-05, wd=0.0005\n",
      "\n",
      "========================================================================================================================\n",
      "DETAILED ANALYSIS BY CONFIGURATION\n",
      "========================================================================================================================\n",
      "\n",
      "1. BY INPUT TYPE:\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "           test_f1                                 overfit_gap          \\\n",
      "             count    mean     std     min     max        mean     std   \n",
      "input_type                                                               \n",
      "combined         5  0.8595  0.0054  0.8500  0.8632      0.0976  0.0311   \n",
      "concat          46  0.8193  0.0463  0.7397  0.8740      0.0759  0.0226   \n",
      "difference       4  0.7736  0.0701  0.7121  0.8432      0.1153  0.0439   \n",
      "\n",
      "           test_precision test_recall test_auc best_epoch  \n",
      "                     mean        mean     mean       mean  \n",
      "input_type                                                 \n",
      "combined           0.8322      0.8894   0.9159     39.200  \n",
      "concat             0.7621      0.8915   0.8748     23.587  \n",
      "difference         0.7158      0.8473   0.8276     16.750  \n",
      "\n",
      "ANOVA F-statistic: 3.8359, p-value: 2.7931e-02\n",
      "  â†’ Statistically significant differences detected!\n",
      "\n",
      "2. BY DROPOUT RATE:\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "        test_f1                                 overfit_gap          \\\n",
      "          count    mean     std     min     max        mean     std   \n",
      "dropout                                                               \n",
      "0.00          1  0.8618     NaN  0.8618  0.8618      0.1121     NaN   \n",
      "0.30          2  0.8174  0.0581  0.7762  0.8585      0.0887  0.0057   \n",
      "0.40         31  0.8243  0.0444  0.7415  0.8717      0.0856  0.0250   \n",
      "0.50          8  0.8441  0.0323  0.7692  0.8740      0.0725  0.0306   \n",
      "0.55          2  0.7892  0.0686  0.7406  0.8377      0.0715  0.0568   \n",
      "0.60          6  0.8137  0.0588  0.7121  0.8621      0.0707  0.0247   \n",
      "0.70          5  0.7633  0.0525  0.7143  0.8500      0.0698  0.0338   \n",
      "\n",
      "        test_precision test_recall test_auc best_epoch  \n",
      "                  mean        mean     mean       mean  \n",
      "dropout                                                 \n",
      "0.00            0.8011      0.9325   0.9160    41.0000  \n",
      "0.30            0.7517      0.9003   0.8767    11.5000  \n",
      "0.40            0.7658      0.8967   0.8803    23.4516  \n",
      "0.50            0.8216      0.8714   0.9068    36.8750  \n",
      "0.55            0.7202      0.8810   0.8299    14.0000  \n",
      "0.60            0.7713      0.8655   0.8718    27.8333  \n",
      "0.70            0.6790      0.8778   0.8059    13.4000  \n",
      "\n",
      "ANOVA F-statistic: 2.1815, p-value: 7.1709e-02\n",
      "  â†’ No significant differences (might just be noise)\n",
      "\n",
      "3. BY LEARNING RATE:\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "        test_f1                                 overfit_gap          \\\n",
      "          count    mean     std     min     max        mean     std   \n",
      "lr                                                                    \n",
      "0.00005       2  0.7701  0.0015  0.7690  0.7712      0.0351  0.0115   \n",
      "0.00010       4  0.7373  0.0286  0.7121  0.7692      0.0755  0.0140   \n",
      "0.00020       1  0.7733     NaN  0.7733  0.7733      0.0720     NaN   \n",
      "0.00030       1  0.8377     NaN  0.8377  0.8377      0.0313     NaN   \n",
      "0.00050       7  0.8387  0.0449  0.7406  0.8740      0.0800  0.0355   \n",
      "0.00100      39  0.8268  0.0437  0.7397  0.8717      0.0850  0.0252   \n",
      "0.00500       1  0.8620     NaN  0.8620  0.8620      0.0893     NaN   \n",
      "\n",
      "        test_precision test_recall test_auc best_epoch  \n",
      "                  mean        mean     mean       mean  \n",
      "lr                                                      \n",
      "0.00005         0.6812      0.8859   0.8265    17.5000  \n",
      "0.00010         0.6515      0.8497   0.7904     3.5000  \n",
      "0.00020         0.6814      0.8939   0.8314     3.0000  \n",
      "0.00030         0.8065      0.8714   0.8920    27.0000  \n",
      "0.00050         0.8108      0.8746   0.8982    39.0000  \n",
      "0.00100         0.7724      0.8945   0.8817    24.4872  \n",
      "0.00500         0.8240      0.9035   0.9187    41.0000  \n",
      "\n",
      "ANOVA F-statistic: 6.7194, p-value: 7.0711e-04\n",
      "  â†’ Statistically significant differences detected!\n",
      "\n",
      "4. BY WEIGHT DECAY:\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "             test_f1                                 overfit_gap          \\\n",
      "               count    mean     std     min     max        mean     std   \n",
      "weight_decay                                                               \n",
      "0.00000           29  0.8239  0.0456  0.7413  0.8674      0.0862  0.0267   \n",
      "0.00001            1  0.7712     NaN  0.7712  0.7712      0.0941     NaN   \n",
      "0.00005            2  0.7703  0.0015  0.7692  0.7713      0.0835  0.0155   \n",
      "0.00010           16  0.8295  0.0504  0.7121  0.8740      0.0800  0.0268   \n",
      "0.00020            1  0.8377     NaN  0.8377  0.8377      0.0313     NaN   \n",
      "0.00050            5  0.7854  0.0632  0.7143  0.8520      0.0599  0.0280   \n",
      "0.00100            1  0.8356     NaN  0.8356  0.8356      0.0656     NaN   \n",
      "\n",
      "             test_precision test_recall test_auc best_epoch  \n",
      "                       mean        mean     mean       mean  \n",
      "weight_decay                                                 \n",
      "0.00000              0.7678      0.8938   0.8785    23.8276  \n",
      "0.00001              0.6780      0.8939   0.8299     1.0000  \n",
      "0.00005              0.6777      0.8923   0.8264     2.0000  \n",
      "0.00010              0.7888      0.8802   0.8874    31.8750  \n",
      "0.00020              0.8065      0.8714   0.8920    27.0000  \n",
      "0.00050              0.7130      0.8804   0.8355    18.2000  \n",
      "0.00100              0.7869      0.8907   0.9040    24.0000  \n",
      "\n",
      "ANOVA F-statistic: 1.8269, p-value: 1.5485e-01\n",
      "  â†’ No significant differences (might just be noise)\n",
      "\n",
      "5. BY BATCH SIZE:\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "           test_f1                                 overfit_gap          \\\n",
      "             count    mean     std     min     max        mean     std   \n",
      "batch_size                                                               \n",
      "32               3  0.8317  0.0543  0.7692  0.8674      0.0864  0.0147   \n",
      "64              49  0.8212  0.0485  0.7121  0.8740      0.0811  0.0274   \n",
      "128              2  0.8014  0.0427  0.7712  0.8316      0.0496  0.0320   \n",
      "256              1  0.7415     NaN  0.7415  0.7415      0.1042     NaN   \n",
      "\n",
      "           test_precision test_recall test_auc best_epoch  \n",
      "                     mean        mean     mean       mean  \n",
      "batch_size                                                 \n",
      "32                 0.7820      0.8917   0.8861    25.6667  \n",
      "64                 0.7683      0.8874   0.8772    24.9592  \n",
      "128                0.7313      0.8875   0.8645    23.5000  \n",
      "256                0.6242      0.9132   0.7604     1.0000  \n",
      "\n",
      "ANOVA F-statistic: 0.2355, p-value: 7.9104e-01\n",
      "  â†’ No significant differences (might just be noise)\n",
      "\n",
      "6. BY NETWORK DEPTH:\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "           test_f1                                 overfit_gap          \\\n",
      "             count    mean     std     min     max        mean     std   \n",
      "num_layers                                                               \n",
      "1                1  0.7460     NaN  0.7460  0.7460      0.0947     NaN   \n",
      "2                8  0.8139  0.0635  0.7121  0.8673      0.0835  0.0402   \n",
      "3               44  0.8204  0.0459  0.7397  0.8740      0.0790  0.0249   \n",
      "4                1  0.8632     NaN  0.8632  0.8632      0.1198     NaN   \n",
      "5                1  0.8606     NaN  0.8606  0.8606      0.0797     NaN   \n",
      "\n",
      "           test_precision test_recall test_auc best_epoch  \n",
      "                     mean        mean     mean       mean  \n",
      "num_layers                                                 \n",
      "1                  0.6384      0.8971   0.7811     1.0000  \n",
      "2                  0.7758      0.8605   0.8704    26.1250  \n",
      "3                  0.7640      0.8913   0.8762    24.4318  \n",
      "4                  0.8107      0.9228   0.9177    32.0000  \n",
      "5                  0.8062      0.9228   0.9165    31.0000  \n",
      "\n",
      "ANOVA F-statistic: 0.1208, p-value: 7.2966e-01\n",
      "  â†’ No significant differences (might just be noise)\n",
      "\n",
      "7. BY EARLY STOPPING PATIENCE:\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "         test_f1                                 overfit_gap          \\\n",
      "           count    mean     std     min     max        mean     std   \n",
      "patience                                                               \n",
      "5              1  0.7705     NaN  0.7705  0.7705      0.0492     NaN   \n",
      "10             1  0.7705     NaN  0.7705  0.7705      0.0783     NaN   \n",
      "15            47  0.8237  0.0487  0.7121  0.8740      0.0822  0.0277   \n",
      "20             4  0.7802  0.0410  0.7406  0.8377      0.0719  0.0328   \n",
      "25             1  0.8523     NaN  0.8523  0.8523      0.0798     NaN   \n",
      "30             1  0.8523     NaN  0.8523  0.8523      0.0798     NaN   \n",
      "\n",
      "         test_precision test_recall test_auc best_epoch  \n",
      "                   mean        mean     mean       mean  \n",
      "patience                                                 \n",
      "5                0.6789      0.8907   0.8292     1.0000  \n",
      "10               0.6789      0.8907   0.8292     1.0000  \n",
      "15               0.7717      0.8886   0.8795    26.6383  \n",
      "20               0.7006      0.8850   0.8285     8.5000  \n",
      "25               0.8253      0.8810   0.9115    30.0000  \n",
      "30               0.8253      0.8810   0.9115    30.0000  \n",
      "\n",
      "ANOVA F-statistic: 2.9878, p-value: 9.0191e-02\n",
      "  â†’ No significant differences (might just be noise)\n",
      "\n",
      "8. BY ARCHITECTURE SIZE:\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "          test_f1                                 overfit_gap          \\\n",
      "            count    mean     std     min     max        mean     std   \n",
      "arch_size                                                               \n",
      "tiny            1  0.7460     NaN  0.7460  0.7460      0.0947     NaN   \n",
      "small           5  0.8142  0.0565  0.7143  0.8471      0.0784  0.0522   \n",
      "medium         33  0.8122  0.0502  0.7121  0.8740      0.0809  0.0232   \n",
      "large           8  0.8310  0.0389  0.7692  0.8621      0.0704  0.0347   \n",
      "huge            8  0.8512  0.0329  0.7733  0.8717      0.0899  0.0154   \n",
      "\n",
      "          test_precision test_recall test_auc best_epoch  \n",
      "                    mean        mean     mean       mean  \n",
      "arch_size                                                 \n",
      "tiny              0.6384      0.8971   0.7811     1.0000  \n",
      "small             0.7758      0.8617   0.8735    24.2000  \n",
      "medium            0.7548      0.8859   0.8674    22.0606  \n",
      "large             0.7818      0.8895   0.8879    28.6250  \n",
      "huge              0.7999      0.9112   0.9069    33.6250  \n",
      "\n",
      "ANOVA F-statistic: 1.6216, p-value: 1.9611e-01\n",
      "  â†’ No significant differences (might just be noise)\n",
      "\n",
      "========================================================================================================================\n",
      "DEEP DIVE: CONCAT INPUT EXPERIMENTS\n",
      "========================================================================================================================\n",
      "\n",
      "Total concat experiments: 46\n",
      "Best F1: 0.8740\n",
      "Worst F1: 0.7397\n",
      "Mean F1: 0.8193 Â± 0.0463\n",
      "Median overfit gap: 0.0790\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "OPTIMAL HYPERPARAMETERS FOR CONCAT:\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "DROPOUT:\n",
      "  Best single model: 0.5\n",
      "  Top 5 average: 0.420000\n",
      "  Distribution in top 5:\n",
      "    0.4: 4/5\n",
      "    0.5: 1/5\n",
      "\n",
      "LR:\n",
      "  Best single model: 0.0005\n",
      "  Top 5 average: 0.000900\n",
      "  Distribution in top 5:\n",
      "    0.001: 4/5\n",
      "    0.0005: 1/5\n",
      "\n",
      "WEIGHT_DECAY:\n",
      "  Best single model: 0.0001\n",
      "  Top 5 average: 0.000060\n",
      "  Distribution in top 5:\n",
      "    0.0001: 3/5\n",
      "    0.0: 2/5\n",
      "\n",
      "BATCH_SIZE:\n",
      "  Best single model: 64\n",
      "  Top 5 average: 57.600000\n",
      "  Distribution in top 5:\n",
      "    64: 4/5\n",
      "    32: 1/5\n",
      "\n",
      "HIDDEN_DIMS:\n",
      "  Best single model: [512, 256, 128]\n",
      "  Most common in top 5: [512, 256, 128]\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "HYPERPARAMETER CORRELATIONS WITH F1:\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "             dropout: -0.2755\n",
      "                  lr:  0.2322\n",
      "        weight_decay: -0.0321\n",
      "          batch_size: -0.2731\n",
      "  total_hidden_units:  0.2955\n",
      "          num_layers:  0.1008\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "SWEET SPOT RANGES (values where F1 > median):\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "dropout: [0.000000, 0.600000]\n",
      "lr: [0.000500, 0.005000]\n",
      "weight_decay: [0.000000, 0.000500]\n",
      "\n",
      "========================================================================================================================\n",
      "REGULARIZATION ANALYSIS\n",
      "========================================================================================================================\n",
      "\n",
      "Performance by regularization strength:\n",
      "             test_f1                         overfit_gap          \\\n",
      "               count    mean     std     max        mean     std   \n",
      "reg_category                                                       \n",
      "minimal           29  0.8239  0.0456  0.8674      0.0862  0.0267   \n",
      "light             22  0.8231  0.0479  0.8740      0.0769  0.0260   \n",
      "moderate           4  0.7688  0.0589  0.8500      0.0612  0.0322   \n",
      "heavy              0     NaN     NaN     NaN         NaN     NaN   \n",
      "\n",
      "             test_precision test_recall  \n",
      "                       mean        mean  \n",
      "reg_category                             \n",
      "minimal              0.7678      0.8938  \n",
      "light                0.7751      0.8832  \n",
      "moderate             0.6904      0.8738  \n",
      "heavy                   NaN         NaN  \n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "OVERFITTING STATISTICS:\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Models with overfit_gap > 0.15: 1/55\n",
      "Models with overfit_gap < 0.05: 7/55\n",
      "Models with negative gap (test > train): 0/55\n",
      "\n",
      "Best well-generalized model (|gap| < 0.10):\n",
      "  concat_best_seed2\n",
      "  F1: 0.8740, Gap: 0.0398\n",
      "  Config: dropout=0.5, wd=0.0001\n",
      "\n",
      "========================================================================================================================\n",
      "PRECISION-RECALL TRADEOFF ANALYSIS\n",
      "========================================================================================================================\n",
      "\n",
      "Top 10 models by F1 with precision-recall breakdown:\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      " 1. concat_best_seed2                   F1:0.8740  P:0.8464  R:0.9035  [recall-biased]\n",
      " 2. concat_minimal_compression          F1:0.8717  P:0.8393  R:0.9068  [recall-biased]\n",
      " 3. concat_wide_v2                      F1:0.8689  P:0.8261  R:0.9164  [recall-biased]\n",
      " 4. concat_batch_32                     F1:0.8674  P:0.8424  R:0.8939  [recall-biased]\n",
      " 5. concat_ablate_wider                 F1:0.8673  P:0.8338  R:0.9035  [recall-biased]\n",
      " 6. concat_best_seed4                   F1:0.8661  P:0.8488  R:0.8842  [balanced]\n",
      " 7. concat_extra_large                  F1:0.8645  P:0.8130  R:0.9228  [recall-biased]\n",
      " 8. combined_large                      F1:0.8632  P:0.8107  R:0.9228  [recall-biased]\n",
      " 9. combined_regularized                F1:0.8621  P:0.8410  R:0.8842  [balanced]\n",
      "10. concat_lr_5e3                       F1:0.8620  P:0.8240  R:0.9035  [recall-biased]\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "PARETO FRONTIER (models where you can't improve one metric without hurting the other):\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Found 8 Pareto-optimal models:\n",
      "  concat_best_seed2                   P:0.8464  R:0.9035  F1:0.8740\n",
      "  concat_minimal_compression          P:0.8393  R:0.9068  F1:0.8717\n",
      "  concat_wide_v2                      P:0.8261  R:0.9164  F1:0.8689\n",
      "  concat_best_seed4                   P:0.8488  R:0.8842  F1:0.8661\n",
      "  concat_extra_large                  P:0.8130  R:0.9228  F1:0.8645\n",
      "  concat_ablate_no_dropout            P:0.8011  R:0.9325  F1:0.8618\n",
      "  combined_small                      P:0.8567  R:0.8650  F1:0.8608\n",
      "  concat_best_seed3                   P:0.8789  R:0.8167  F1:0.8467\n",
      "\n",
      "========================================================================================================================\n",
      "RANDOM SEED VARIANCE ANALYSIS\n",
      "========================================================================================================================\n",
      "\n",
      "Found 1 configurations with multiple seeds:\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "concat_best:\n",
      "  Runs: 4\n",
      "  F1: 0.8574 Â± 0.0150 (range: [0.8429, 0.8740])\n",
      "  Precision: 0.8536 Â± 0.0173\n",
      "  Recall: 0.8625 Â± 0.0389\n",
      "  Overfit gap: 0.0554 Â± 0.0115\n",
      "\n",
      "âœ… Detailed results exported to /net/home/lmaecker/own_projects/burned_embedder/experiments_more/detailed_results.csv\n",
      "\n",
      "========================================================================================================================\n",
      "âœ… ANALYSIS COMPLETE!\n",
      "========================================================================================================================\n",
      "\n",
      "Results saved to: /net/home/lmaecker/own_projects/burned_embedder/experiments_more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2058201/2959291509.py:150: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  analysis = df.groupby(group_col).agg({\n",
      "/tmp/ipykernel_2058201/2959291509.py:162: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  groups = [group['test_f1'].values for name, group in df.groupby(group_col) if len(group) >= 2]\n",
      "/tmp/ipykernel_2058201/2959291509.py:280: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  reg_analysis = df.groupby('reg_category').agg({\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def main():\n",
    "    \"\"\"Main analysis function\"\"\"\n",
    "    results, summary_file = load_experiment_results(folder_name=\"experiments_more\")\n",
    "    \n",
    "    if not results:\n",
    "        print(\"No experiment results found!\")\n",
    "        return\n",
    "    \n",
    "    df = results_to_dataframe(results)\n",
    "    save_dir = root_path / \"experiments_more\"\n",
    "    \n",
    "    # Run text analyses\n",
    "    print_summary_table(df, top_n=20)\n",
    "    analyze_by_category(df)\n",
    "    deep_dive_concat(df)\n",
    "    analyze_regularization_tradeoffs(df)\n",
    "    analyze_precision_recall_tradeoff(df)\n",
    "    analyze_seed_variance(df)\n",
    "    \n",
    "    # Export to CSV\n",
    "    export_results_csv(df, save_dir)\n",
    "    \n",
    "    print(f\"\\n{'='*120}\")\n",
    "    print(\"âœ… ANALYSIS COMPLETE!\")\n",
    "    print(f\"{'='*120}\")\n",
    "    print(f\"\\nResults saved to: {save_dir}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4e26a680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading most recent summary: summary_20250929_193213.json\n",
      "\n",
      "========================================================================================================================\n",
      "EXPERIMENT RESULTS SUMMARY\n",
      "========================================================================================================================\n",
      "\n",
      "Rank  Experiment                         F1      Prec    Recall  AUC     Overfit   Epoch  \n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "1     second_best_seed1                  0.8722  0.8667  0.8778  0.9386  0.0921    46     \n",
      "2     second_best_seed2                  0.8717  0.8393  0.9068  0.9201  0.0958    53     \n",
      "3     second_best_seed4                  0.8665  0.8378  0.8971  0.9313  0.0570    25     \n",
      "4     best_model_seed4                   0.8661  0.8488  0.8842  0.9328  0.0539    50     \n",
      "5     second_best_seed3                  0.8494  0.8466  0.8521  0.9243  0.0905    27     \n",
      "6     best_model_seed3                   0.8467  0.8789  0.8167  0.9241  0.0647    37     \n",
      "7     best_model_seed1                   0.8429  0.8403  0.8457  0.9223  0.0631    34     \n",
      "8     best_model_seed2                   0.7443  0.6376  0.8939  0.7782  0.1061    1      \n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "BOTTOM 5 PERFORMERS:\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "4     best_model_seed4                   0.8661  0.8488  0.8842  0.9328  0.0539    50     \n",
      "5     second_best_seed3                  0.8494  0.8466  0.8521  0.9243  0.0905    27     \n",
      "6     best_model_seed3                   0.8467  0.8789  0.8167  0.9241  0.0647    37     \n",
      "7     best_model_seed1                   0.8429  0.8403  0.8457  0.9223  0.0631    34     \n",
      "8     best_model_seed2                   0.7443  0.6376  0.8939  0.7782  0.1061    1      \n",
      "\n",
      "========================================================================================================================\n",
      "BEST MODELS BY METRIC\n",
      "========================================================================================================================\n",
      "\n",
      "F1 Score:\n",
      "  Model: second_best_seed1\n",
      "  Value: 0.8722\n",
      "  Config: input=concat, arch=[1400, 700, 350], dropout=0.4, lr=0.001, wd=0.0001\n",
      "\n",
      "Precision:\n",
      "  Model: best_model_seed3\n",
      "  Value: 0.8789\n",
      "  Config: input=concat, arch=[512, 256, 128], dropout=0.5, lr=0.0005, wd=0.0001\n",
      "\n",
      "Recall:\n",
      "  Model: second_best_seed2\n",
      "  Value: 0.9068\n",
      "  Config: input=concat, arch=[1400, 700, 350], dropout=0.4, lr=0.001, wd=0.0001\n",
      "\n",
      "AUC:\n",
      "  Model: second_best_seed1\n",
      "  Value: 0.9386\n",
      "  Config: input=concat, arch=[1400, 700, 350], dropout=0.4, lr=0.001, wd=0.0001\n",
      "\n",
      "Least Overfit:\n",
      "  Model: best_model_seed4\n",
      "  Value: 0.0539\n",
      "  Config: input=concat, arch=[512, 256, 128], dropout=0.5, lr=0.0005, wd=0.0001\n",
      "\n",
      "Fastest Convergence:\n",
      "  Model: best_model_seed2\n",
      "  Value: 1.0000\n",
      "  Config: input=concat, arch=[512, 256, 128], dropout=0.5, lr=0.0005, wd=0.0001\n",
      "\n",
      "Best Val-Test Agreement:\n",
      "  Model: best_model_seed4\n",
      "  Value: 0.0539\n",
      "  Config: input=concat, arch=[512, 256, 128], dropout=0.5, lr=0.0005, wd=0.0001\n",
      "\n",
      "========================================================================================================================\n",
      "DETAILED ANALYSIS BY CONFIGURATION\n",
      "========================================================================================================================\n",
      "\n",
      "1. BY INPUT TYPE:\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "           test_f1                                overfit_gap          \\\n",
      "             count   mean     std     min     max        mean     std   \n",
      "input_type                                                              \n",
      "concat           8  0.845  0.0423  0.7443  0.8722      0.0779  0.0203   \n",
      "\n",
      "           test_precision test_recall test_auc best_epoch  \n",
      "                     mean        mean     mean       mean  \n",
      "input_type                                                 \n",
      "concat             0.8245      0.8718    0.909     34.125  \n",
      "\n",
      "2. BY DROPOUT RATE:\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "        test_f1                                 overfit_gap          \\\n",
      "          count    mean     std     min     max        mean     std   \n",
      "dropout                                                               \n",
      "0.4           4  0.8649  0.0107  0.8494  0.8722      0.0838  0.0180   \n",
      "0.5           4  0.8250  0.0548  0.7443  0.8661      0.0720  0.0233   \n",
      "\n",
      "        test_precision test_recall test_auc best_epoch  \n",
      "                  mean        mean     mean       mean  \n",
      "dropout                                                 \n",
      "0.4             0.8476      0.8834   0.9286      37.75  \n",
      "0.5             0.8014      0.8601   0.8894      30.50  \n",
      "\n",
      "ANOVA F-statistic: 2.0475, p-value: 2.0241e-01\n",
      "  â†’ No significant differences (might just be noise)\n",
      "\n",
      "3. BY LEARNING RATE:\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "       test_f1                                 overfit_gap          \\\n",
      "         count    mean     std     min     max        mean     std   \n",
      "lr                                                                   \n",
      "0.0005       4  0.8250  0.0548  0.7443  0.8661      0.0720  0.0233   \n",
      "0.0010       4  0.8649  0.0107  0.8494  0.8722      0.0838  0.0180   \n",
      "\n",
      "       test_precision test_recall test_auc best_epoch  \n",
      "                 mean        mean     mean       mean  \n",
      "lr                                                     \n",
      "0.0005         0.8014      0.8601   0.8894      30.50  \n",
      "0.0010         0.8476      0.8834   0.9286      37.75  \n",
      "\n",
      "ANOVA F-statistic: 2.0475, p-value: 2.0241e-01\n",
      "  â†’ No significant differences (might just be noise)\n",
      "\n",
      "4. BY WEIGHT DECAY:\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "             test_f1                                overfit_gap          \\\n",
      "               count   mean     std     min     max        mean     std   \n",
      "weight_decay                                                              \n",
      "0.0001             8  0.845  0.0423  0.7443  0.8722      0.0779  0.0203   \n",
      "\n",
      "             test_precision test_recall test_auc best_epoch  \n",
      "                       mean        mean     mean       mean  \n",
      "weight_decay                                                 \n",
      "0.0001               0.8245      0.8718    0.909     34.125  \n",
      "\n",
      "5. BY BATCH SIZE:\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "           test_f1                                overfit_gap          \\\n",
      "             count   mean     std     min     max        mean     std   \n",
      "batch_size                                                              \n",
      "64               8  0.845  0.0423  0.7443  0.8722      0.0779  0.0203   \n",
      "\n",
      "           test_precision test_recall test_auc best_epoch  \n",
      "                     mean        mean     mean       mean  \n",
      "batch_size                                                 \n",
      "64                 0.8245      0.8718    0.909     34.125  \n",
      "\n",
      "6. BY NETWORK DEPTH:\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "           test_f1                                overfit_gap          \\\n",
      "             count   mean     std     min     max        mean     std   \n",
      "num_layers                                                              \n",
      "3                8  0.845  0.0423  0.7443  0.8722      0.0779  0.0203   \n",
      "\n",
      "           test_precision test_recall test_auc best_epoch  \n",
      "                     mean        mean     mean       mean  \n",
      "num_layers                                                 \n",
      "3                  0.8245      0.8718    0.909     34.125  \n",
      "\n",
      "8. BY ARCHITECTURE SIZE:\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "          test_f1                                 overfit_gap          \\\n",
      "            count    mean     std     min     max        mean     std   \n",
      "arch_size                                                               \n",
      "tiny            0     NaN     NaN     NaN     NaN         NaN     NaN   \n",
      "small           0     NaN     NaN     NaN     NaN         NaN     NaN   \n",
      "medium          4  0.8250  0.0548  0.7443  0.8661      0.0720  0.0233   \n",
      "large           0     NaN     NaN     NaN     NaN         NaN     NaN   \n",
      "huge            4  0.8649  0.0107  0.8494  0.8722      0.0838  0.0180   \n",
      "\n",
      "          test_precision test_recall test_auc best_epoch  \n",
      "                    mean        mean     mean       mean  \n",
      "arch_size                                                 \n",
      "tiny                 NaN         NaN      NaN        NaN  \n",
      "small                NaN         NaN      NaN        NaN  \n",
      "medium            0.8014      0.8601   0.8894      30.50  \n",
      "large                NaN         NaN      NaN        NaN  \n",
      "huge              0.8476      0.8834   0.9286      37.75  \n",
      "\n",
      "ANOVA F-statistic: 2.0475, p-value: 2.0241e-01\n",
      "  â†’ No significant differences (might just be noise)\n",
      "\n",
      "========================================================================================================================\n",
      "DEEP DIVE: CONCAT INPUT EXPERIMENTS\n",
      "========================================================================================================================\n",
      "\n",
      "Total concat experiments: 8\n",
      "Best F1: 0.8722\n",
      "Worst F1: 0.7443\n",
      "Mean F1: 0.8450 Â± 0.0423\n",
      "Median overfit gap: 0.0776\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "OPTIMAL HYPERPARAMETERS FOR CONCAT:\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "DROPOUT:\n",
      "  Best single model: 0.4\n",
      "  Top 5 average: 0.420000\n",
      "  Distribution in top 5:\n",
      "    0.4: 4/5\n",
      "    0.5: 1/5\n",
      "\n",
      "LR:\n",
      "  Best single model: 0.001\n",
      "  Top 5 average: 0.000900\n",
      "  Distribution in top 5:\n",
      "    0.001: 4/5\n",
      "    0.0005: 1/5\n",
      "\n",
      "WEIGHT_DECAY:\n",
      "  Best single model: 0.0001\n",
      "  Top 5 average: 0.000100\n",
      "  Distribution in top 5:\n",
      "    0.0001: 5/5\n",
      "\n",
      "BATCH_SIZE:\n",
      "  Best single model: 64\n",
      "  Top 5 average: 64.000000\n",
      "  Distribution in top 5:\n",
      "    64: 5/5\n",
      "\n",
      "HIDDEN_DIMS:\n",
      "  Best single model: [1400, 700, 350]\n",
      "  Most common in top 5: [1400, 700, 350]\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "HYPERPARAMETER CORRELATIONS WITH F1:\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "             dropout: -0.5044\n",
      "                  lr:  0.5044\n",
      "  total_hidden_units:  0.5044\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "SWEET SPOT RANGES (values where F1 > median):\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "dropout: [0.400000, 0.500000]\n",
      "lr: [0.000500, 0.001000]\n",
      "\n",
      "========================================================================================================================\n",
      "REGULARIZATION ANALYSIS\n",
      "========================================================================================================================\n",
      "\n",
      "Performance by regularization strength:\n",
      "             test_f1                        overfit_gap          \\\n",
      "               count   mean     std     max        mean     std   \n",
      "reg_category                                                      \n",
      "minimal            0    NaN     NaN     NaN         NaN     NaN   \n",
      "light              8  0.845  0.0423  0.8722      0.0779  0.0203   \n",
      "moderate           0    NaN     NaN     NaN         NaN     NaN   \n",
      "heavy              0    NaN     NaN     NaN         NaN     NaN   \n",
      "\n",
      "             test_precision test_recall  \n",
      "                       mean        mean  \n",
      "reg_category                             \n",
      "minimal                 NaN         NaN  \n",
      "light                0.8245      0.8718  \n",
      "moderate                NaN         NaN  \n",
      "heavy                   NaN         NaN  \n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "OVERFITTING STATISTICS:\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Models with overfit_gap > 0.15: 0/8\n",
      "Models with overfit_gap < 0.05: 0/8\n",
      "Models with negative gap (test > train): 0/8\n",
      "\n",
      "Best well-generalized model (|gap| < 0.10):\n",
      "  second_best_seed1\n",
      "  F1: 0.8722, Gap: 0.0921\n",
      "  Config: dropout=0.4, wd=0.0001\n",
      "\n",
      "========================================================================================================================\n",
      "PRECISION-RECALL TRADEOFF ANALYSIS\n",
      "========================================================================================================================\n",
      "\n",
      "Top 10 models by F1 with precision-recall breakdown:\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      " 1. second_best_seed1                   F1:0.8722  P:0.8667  R:0.8778  [balanced]\n",
      " 2. second_best_seed2                   F1:0.8717  P:0.8393  R:0.9068  [recall-biased]\n",
      " 3. second_best_seed4                   F1:0.8665  P:0.8378  R:0.8971  [recall-biased]\n",
      " 4. best_model_seed4                    F1:0.8661  P:0.8488  R:0.8842  [balanced]\n",
      " 5. second_best_seed3                   F1:0.8494  P:0.8466  R:0.8521  [balanced]\n",
      " 6. best_model_seed3                    F1:0.8467  P:0.8789  R:0.8167  [precision-biased]\n",
      " 7. best_model_seed1                    F1:0.8429  P:0.8403  R:0.8457  [balanced]\n",
      " 8. best_model_seed2                    F1:0.7443  P:0.6376  R:0.8939  [recall-biased]\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "PARETO FRONTIER (models where you can't improve one metric without hurting the other):\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Found 4 Pareto-optimal models:\n",
      "  second_best_seed1                   P:0.8667  R:0.8778  F1:0.8722\n",
      "  second_best_seed2                   P:0.8393  R:0.9068  F1:0.8717\n",
      "  best_model_seed4                    P:0.8488  R:0.8842  F1:0.8661\n",
      "  best_model_seed3                    P:0.8789  R:0.8167  F1:0.8467\n",
      "\n",
      "========================================================================================================================\n",
      "RANDOM SEED VARIANCE ANALYSIS\n",
      "========================================================================================================================\n",
      "\n",
      "Found 2 configurations with multiple seeds:\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "best_model:\n",
      "  Runs: 4\n",
      "  F1: 0.8250 Â± 0.0548 (range: [0.7443, 0.8661])\n",
      "  Precision: 0.8014 Â± 0.1104\n",
      "  Recall: 0.8601 Â± 0.0357\n",
      "  Overfit gap: 0.0720 Â± 0.0233\n",
      "  âš ï¸  High variance detected! Results may be unstable.\n",
      "\n",
      "second_best:\n",
      "  Runs: 4\n",
      "  F1: 0.8649 Â± 0.0107 (range: [0.8494, 0.8722])\n",
      "  Precision: 0.8476 Â± 0.0133\n",
      "  Recall: 0.8834 Â± 0.0241\n",
      "  Overfit gap: 0.0838 Â± 0.0180\n",
      "\n",
      "âœ… Detailed results exported to /net/home/lmaecker/own_projects/burned_embedder/experiments_more/detailed_results.csv\n",
      "\n",
      "========================================================================================================================\n",
      "âœ… ANALYSIS COMPLETE!\n",
      "========================================================================================================================\n",
      "\n",
      "Results saved to: /net/home/lmaecker/own_projects/burned_embedder/experiments_more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2058201/2959291509.py:150: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  analysis = df.groupby(group_col).agg({\n",
      "/tmp/ipykernel_2058201/2959291509.py:162: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  groups = [group['test_f1'].values for name, group in df.groupby(group_col) if len(group) >= 2]\n",
      "/tmp/ipykernel_2058201/2959291509.py:280: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  reg_analysis = df.groupby('reg_category').agg({\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def main():\n",
    "    \"\"\"Main analysis function\"\"\"\n",
    "    results, summary_file = load_experiment_results(folder_name=\"experiments_more\")\n",
    "    \n",
    "    if not results:\n",
    "        print(\"No experiment results found!\")\n",
    "        return\n",
    "    \n",
    "    df = results_to_dataframe(results)\n",
    "    save_dir = root_path / \"experiments_more\"\n",
    "    \n",
    "    # Run text analyses\n",
    "    print_summary_table(df, top_n=20)\n",
    "    analyze_by_category(df)\n",
    "    deep_dive_concat(df)\n",
    "    analyze_regularization_tradeoffs(df)\n",
    "    analyze_precision_recall_tradeoff(df)\n",
    "    analyze_seed_variance(df)\n",
    "    \n",
    "    # Export to CSV\n",
    "    export_results_csv(df, save_dir)\n",
    "    \n",
    "    print(f\"\\n{'='*120}\")\n",
    "    print(\"âœ… ANALYSIS COMPLETE!\")\n",
    "    print(f\"{'='*120}\")\n",
    "    print(f\"\\nResults saved to: {save_dir}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c80fd40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # scripts/analyze_experiments.py\n",
    "\n",
    "# import json\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# from pathlib import Path\n",
    "# import rootutils\n",
    "\n",
    "# root_path = rootutils.find_root()\n",
    "\n",
    "# def load_experiment_results(summary_file=None):\n",
    "#     \"\"\"Load experiment results from JSON file\"\"\"\n",
    "#     experiments_dir = root_path / \"experiments\"\n",
    "    \n",
    "#     if summary_file is None:\n",
    "#         # Find the most recent summary file\n",
    "#         summary_files = sorted(experiments_dir.glob(\"summary_*.json\"))\n",
    "#         if not summary_files:\n",
    "#             raise FileNotFoundError(\"No summary files found in experiments directory\")\n",
    "#         summary_file = summary_files[-1]\n",
    "#         print(f\"Loading most recent summary: {summary_file.name}\")\n",
    "#     else:\n",
    "#         summary_file = Path(summary_file)\n",
    "    \n",
    "#     with open(summary_file, 'r') as f:\n",
    "#         results = json.load(f)\n",
    "    \n",
    "#     return results, summary_file\n",
    "\n",
    "\n",
    "# def results_to_dataframe(results):\n",
    "#     \"\"\"Convert results list to pandas DataFrame\"\"\"\n",
    "#     if not results:\n",
    "#         raise ValueError(\"No results to analyze - all experiments failed\")\n",
    "    \n",
    "#     data = []\n",
    "#     for result in results:\n",
    "#         row = {\n",
    "#             'experiment': result['experiment_name'],\n",
    "#             'test_f1': result['test_f1'],\n",
    "#             'test_precision': result['test_precision'],\n",
    "#             'test_recall': result['test_recall'],\n",
    "#             'test_auc': result['test_roc_auc'],\n",
    "#             'val_f1': result['best_val_f1'],\n",
    "#             'overfit_gap': result['overfit_gap'],\n",
    "#             'best_epoch': result['best_epoch'],\n",
    "#             'input_type': result['config']['input_type'],\n",
    "#             'hidden_dims': str(result['config']['hidden_dims']),\n",
    "#             'dropout': result['config']['dropout'],\n",
    "#             'lr': result['config']['lr'],\n",
    "#             'weight_decay': result['config']['weight_decay'],\n",
    "#             'batch_size': result['config']['batch_size'],\n",
    "#         }\n",
    "#         data.append(row)\n",
    "    \n",
    "#     df = pd.DataFrame(data)\n",
    "#     return df\n",
    "\n",
    "\n",
    "# def print_summary_table(df):\n",
    "#     \"\"\"Print formatted summary table\"\"\"\n",
    "#     print(\"\\n\" + \"=\"*100)\n",
    "#     print(\"EXPERIMENT RESULTS SUMMARY\")\n",
    "#     print(\"=\"*100)\n",
    "    \n",
    "#     # Sort by test F1\n",
    "#     df_sorted = df.sort_values('test_f1', ascending=False)\n",
    "    \n",
    "#     print(f\"\\n{'Rank':<6}{'Experiment':<30}{'F1':<8}{'Prec':<8}{'Recall':<8}{'AUC':<8}{'Overfit':<10}\")\n",
    "#     print(\"-\"*100)\n",
    "    \n",
    "#     for idx, (_, row) in enumerate(df_sorted.iterrows(), 1):\n",
    "#         print(f\"{idx:<6}{row['experiment']:<30}{row['test_f1']:<8.4f}{row['test_precision']:<8.4f}\"\n",
    "#               f\"{row['test_recall']:<8.4f}{row['test_auc']:<8.4f}{row['overfit_gap']:<10.4f}\")\n",
    "    \n",
    "#     # Print best models by different metrics\n",
    "#     print(f\"\\n\" + \"=\"*100)\n",
    "#     print(\"BEST MODELS BY METRIC\")\n",
    "#     print(\"=\"*100)\n",
    "    \n",
    "#     print(f\"\\nBest F1 Score:      {df_sorted.iloc[0]['experiment']:<30} (F1: {df_sorted.iloc[0]['test_f1']:.4f})\")\n",
    "#     print(f\"Best Precision:     {df.loc[df['test_precision'].idxmax(), 'experiment']:<30} \"\n",
    "#           f\"(Prec: {df['test_precision'].max():.4f})\")\n",
    "#     print(f\"Best Recall:        {df.loc[df['test_recall'].idxmax(), 'experiment']:<30} \"\n",
    "#           f\"(Recall: {df['test_recall'].max():.4f})\")\n",
    "#     print(f\"Best AUC:           {df.loc[df['test_auc'].idxmax(), 'experiment']:<30} \"\n",
    "#           f\"(AUC: {df['test_auc'].max():.4f})\")\n",
    "#     print(f\"Least Overfit:      {df.loc[df['overfit_gap'].idxmin(), 'experiment']:<30} \"\n",
    "#           f\"(Gap: {df['overfit_gap'].min():.4f})\")\n",
    "\n",
    "\n",
    "# def analyze_by_category(df):\n",
    "#     \"\"\"Analyze results by different configuration categories\"\"\"\n",
    "#     print(f\"\\n\" + \"=\"*100)\n",
    "#     print(\"ANALYSIS BY CONFIGURATION\")\n",
    "#     print(\"=\"*100)\n",
    "    \n",
    "#     # By input type\n",
    "#     print(\"\\n1. By Input Type:\")\n",
    "#     input_analysis = df.groupby('input_type').agg({\n",
    "#         'test_f1': ['mean', 'std', 'max'],\n",
    "#         'overfit_gap': 'mean'\n",
    "#     }).round(4)\n",
    "#     print(input_analysis)\n",
    "    \n",
    "#     # By dropout\n",
    "#     print(\"\\n2. By Dropout Rate:\")\n",
    "#     dropout_analysis = df.groupby('dropout').agg({\n",
    "#         'test_f1': ['mean', 'std', 'max'],\n",
    "#         'overfit_gap': 'mean'\n",
    "#     }).round(4)\n",
    "#     print(dropout_analysis)\n",
    "    \n",
    "#     # By learning rate\n",
    "#     print(\"\\n3. By Learning Rate:\")\n",
    "#     lr_analysis = df.groupby('lr').agg({\n",
    "#         'test_f1': ['mean', 'std', 'max'],\n",
    "#         'overfit_gap': 'mean'\n",
    "#     }).round(4)\n",
    "#     print(lr_analysis)\n",
    "    \n",
    "#     # By weight decay\n",
    "#     print(\"\\n4. By Weight Decay:\")\n",
    "#     wd_analysis = df.groupby('weight_decay').agg({\n",
    "#         'test_f1': ['mean', 'std', 'max'],\n",
    "#         'overfit_gap': 'mean'\n",
    "#     }).round(4)\n",
    "#     print(wd_analysis)\n",
    "\n",
    "\n",
    "# def plot_experiment_comparison(df, save_path=None):\n",
    "#     \"\"\"Create comprehensive visualization of experiment results\"\"\"\n",
    "#     fig = plt.figure(figsize=(20, 12))\n",
    "    \n",
    "#     # Sort by F1 score\n",
    "#     df_sorted = df.sort_values('test_f1', ascending=True)\n",
    "    \n",
    "#     # 1. Main metrics comparison (bar chart)\n",
    "#     ax1 = plt.subplot(3, 3, 1)\n",
    "#     x = np.arange(len(df_sorted))\n",
    "#     width = 0.2\n",
    "    \n",
    "#     ax1.barh(x - width*1.5, df_sorted['test_f1'], width, label='F1', alpha=0.8)\n",
    "#     ax1.barh(x - width*0.5, df_sorted['test_precision'], width, label='Precision', alpha=0.8)\n",
    "#     ax1.barh(x + width*0.5, df_sorted['test_recall'], width, label='Recall', alpha=0.8)\n",
    "#     ax1.barh(x + width*1.5, df_sorted['test_auc'], width, label='AUC', alpha=0.8)\n",
    "    \n",
    "#     ax1.set_yticks(x)\n",
    "#     ax1.set_yticklabels(df_sorted['experiment'], fontsize=8)\n",
    "#     ax1.set_xlabel('Score')\n",
    "#     ax1.set_title('Test Metrics Comparison')\n",
    "#     ax1.legend()\n",
    "#     ax1.grid(axis='x', alpha=0.3)\n",
    "    \n",
    "#     # 2. Overfitting analysis\n",
    "#     ax2 = plt.subplot(3, 3, 2)\n",
    "#     ax2.scatter(df['overfit_gap'], df['test_f1'], s=100, alpha=0.6)\n",
    "#     for idx, row in df.iterrows():\n",
    "#         ax2.annotate(row['experiment'].replace('exp_', ''), \n",
    "#                      (row['overfit_gap'], row['test_f1']), \n",
    "#                      fontsize=7, alpha=0.7)\n",
    "#     ax2.set_xlabel('Overfitting Gap (Train F1 - Test F1)')\n",
    "#     ax2.set_ylabel('Test F1 Score')\n",
    "#     ax2.set_title('Overfitting vs Performance')\n",
    "#     ax2.grid(alpha=0.3)\n",
    "    \n",
    "#     # 3. Precision-Recall tradeoff\n",
    "#     ax3 = plt.subplot(3, 3, 3)\n",
    "#     ax3.scatter(df['test_recall'], df['test_precision'], s=100, alpha=0.6, c=df['test_f1'], \n",
    "#                 cmap='viridis')\n",
    "#     for idx, row in df.iterrows():\n",
    "#         ax3.annotate(row['experiment'].replace('exp_', ''), \n",
    "#                      (row['test_recall'], row['test_precision']), \n",
    "#                      fontsize=7, alpha=0.7)\n",
    "#     ax3.set_xlabel('Recall')\n",
    "#     ax3.set_ylabel('Precision')\n",
    "#     ax3.set_title('Precision-Recall Tradeoff (color=F1)')\n",
    "#     ax3.grid(alpha=0.3)\n",
    "#     plt.colorbar(ax3.collections[0], ax=ax3, label='F1 Score')\n",
    "    \n",
    "#     # 4. Input type comparison\n",
    "#     ax4 = plt.subplot(3, 3, 4)\n",
    "#     input_data = df.groupby('input_type')['test_f1'].agg(['mean', 'std'])\n",
    "#     input_data['mean'].plot(kind='bar', yerr=input_data['std'], ax=ax4, capsize=5)\n",
    "#     ax4.set_xlabel('Input Type')\n",
    "#     ax4.set_ylabel('Test F1 Score')\n",
    "#     ax4.set_title('Performance by Input Type')\n",
    "#     ax4.grid(axis='y', alpha=0.3)\n",
    "#     plt.setp(ax4.xaxis.get_majorticklabels(), rotation=45, ha='right')\n",
    "    \n",
    "#     # 5. Dropout effect\n",
    "#     ax5 = plt.subplot(3, 3, 5)\n",
    "#     dropout_df = df.groupby('dropout').agg({'test_f1': 'mean', 'overfit_gap': 'mean'})\n",
    "#     ax5_twin = ax5.twinx()\n",
    "#     dropout_df['test_f1'].plot(ax=ax5, marker='o', color='blue', label='F1')\n",
    "#     dropout_df['overfit_gap'].plot(ax=ax5_twin, marker='s', color='red', label='Overfit Gap')\n",
    "#     ax5.set_xlabel('Dropout Rate')\n",
    "#     ax5.set_ylabel('Test F1', color='blue')\n",
    "#     ax5_twin.set_ylabel('Overfit Gap', color='red')\n",
    "#     ax5.set_title('Dropout Effect on Performance')\n",
    "#     ax5.grid(alpha=0.3)\n",
    "#     ax5.legend(loc='upper left')\n",
    "#     ax5_twin.legend(loc='upper right')\n",
    "    \n",
    "#     # 6. Learning rate effect\n",
    "#     ax6 = plt.subplot(3, 3, 6)\n",
    "#     lr_df = df.groupby('lr')['test_f1'].mean()\n",
    "#     ax6.plot(lr_df.index, lr_df.values, marker='o', linewidth=2)\n",
    "#     ax6.set_xscale('log')\n",
    "#     ax6.set_xlabel('Learning Rate (log scale)')\n",
    "#     ax6.set_ylabel('Mean Test F1')\n",
    "#     ax6.set_title('Learning Rate Effect')\n",
    "#     ax6.grid(alpha=0.3)\n",
    "    \n",
    "#     # 7. Weight decay effect\n",
    "#     ax7 = plt.subplot(3, 3, 7)\n",
    "#     wd_df = df[df['weight_decay'] > 0].groupby('weight_decay').agg({'test_f1': 'mean', 'overfit_gap': 'mean'})\n",
    "#     if len(wd_df) > 0:\n",
    "#         ax7_twin = ax7.twinx()\n",
    "#         wd_df['test_f1'].plot(ax=ax7, marker='o', color='blue', label='F1')\n",
    "#         wd_df['overfit_gap'].plot(ax=ax7_twin, marker='s', color='red', label='Overfit Gap')\n",
    "#         ax7.set_xscale('log')\n",
    "#         ax7.set_xlabel('Weight Decay (log scale)')\n",
    "#         ax7.set_ylabel('Test F1', color='blue')\n",
    "#         ax7_twin.set_ylabel('Overfit Gap', color='red')\n",
    "#         ax7.set_title('Weight Decay Regularization')\n",
    "#         ax7.grid(alpha=0.3)\n",
    "#         ax7.legend(loc='upper left')\n",
    "#         ax7_twin.legend(loc='upper right')\n",
    "    \n",
    "#     # 8. Model size analysis (count parameters)\n",
    "#     ax8 = plt.subplot(3, 3, 8)\n",
    "#     # Extract total layer sizes as proxy for model size\n",
    "#     df['model_size'] = df['hidden_dims'].apply(lambda x: sum(eval(x)))\n",
    "#     ax8.scatter(df['model_size'], df['test_f1'], s=100, alpha=0.6, c=df['overfit_gap'], \n",
    "#                 cmap='coolwarm')\n",
    "#     ax8.set_xlabel('Model Size (sum of hidden dims)')\n",
    "#     ax8.set_ylabel('Test F1')\n",
    "#     ax8.set_title('Model Size vs Performance (color=overfit)')\n",
    "#     ax8.grid(alpha=0.3)\n",
    "#     plt.colorbar(ax8.collections[0], ax=ax8, label='Overfit Gap')\n",
    "    \n",
    "#     # 9. Training convergence (epochs to best)\n",
    "#     ax9 = plt.subplot(3, 3, 9)\n",
    "#     ax9.scatter(df['best_epoch'], df['test_f1'], s=100, alpha=0.6)\n",
    "#     for idx, row in df.iterrows():\n",
    "#         ax9.annotate(row['experiment'].replace('exp_', ''), \n",
    "#                      (row['best_epoch'], row['test_f1']), \n",
    "#                      fontsize=7, alpha=0.7)\n",
    "#     ax9.set_xlabel('Epoch of Best Validation')\n",
    "#     ax9.set_ylabel('Test F1')\n",
    "#     ax9.set_title('Convergence Speed vs Performance')\n",
    "#     ax9.grid(alpha=0.3)\n",
    "    \n",
    "#     plt.tight_layout()\n",
    "    \n",
    "#     if save_path:\n",
    "#         plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "#         print(f\"\\nVisualization saved to {save_path}\")\n",
    "    \n",
    "#     plt.show()\n",
    "\n",
    "\n",
    "# def plot_top_models_confusion(results, top_n=3, save_path=None):\n",
    "#     \"\"\"Plot confusion matrices for top N models\"\"\"\n",
    "#     # Sort by F1 score\n",
    "#     sorted_results = sorted(results, key=lambda x: x['test_f1'], reverse=True)\n",
    "#     top_results = sorted_results[:top_n]\n",
    "    \n",
    "#     fig, axes = plt.subplots(1, top_n, figsize=(5*top_n, 4))\n",
    "#     if top_n == 1:\n",
    "#         axes = [axes]\n",
    "    \n",
    "#     for idx, result in enumerate(top_results):\n",
    "#         cm = np.array(result['confusion_matrix'])\n",
    "        \n",
    "#         sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[idx],\n",
    "#                    xticklabels=['Neg', 'Pos'], yticklabels=['Neg', 'Pos'])\n",
    "        \n",
    "#         axes[idx].set_xlabel('Predicted')\n",
    "#         axes[idx].set_ylabel('Actual')\n",
    "#         axes[idx].set_title(f\"{result['experiment_name']}\\nF1: {result['test_f1']:.4f}\")\n",
    "    \n",
    "#     plt.tight_layout()\n",
    "    \n",
    "#     if save_path:\n",
    "#         plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "#         print(f\"Confusion matrices saved to {save_path}\")\n",
    "    \n",
    "#     plt.show()\n",
    "\n",
    "\n",
    "# def generate_recommendations(df):\n",
    "#     \"\"\"Generate recommendations based on experiment results\"\"\"\n",
    "#     print(f\"\\n\" + \"=\"*100)\n",
    "#     print(\"RECOMMENDATIONS\")\n",
    "#     print(\"=\"*100)\n",
    "    \n",
    "#     best_overall = df.loc[df['test_f1'].idxmax()]\n",
    "#     least_overfit = df.loc[df['overfit_gap'].idxmin()]\n",
    "#     best_recall = df.loc[df['test_recall'].idxmax()]\n",
    "#     best_precision = df.loc[df['test_precision'].idxmax()]\n",
    "    \n",
    "#     print(f\"\\n1. Best Overall Performance:\")\n",
    "#     print(f\"   Model: {best_overall['experiment']}\")\n",
    "#     print(f\"   Configuration: input={best_overall['input_type']}, dropout={best_overall['dropout']}, \"\n",
    "#           f\"lr={best_overall['lr']}, wd={best_overall['weight_decay']}\")\n",
    "#     print(f\"   Metrics: F1={best_overall['test_f1']:.4f}, Prec={best_overall['test_precision']:.4f}, \"\n",
    "#           f\"Rec={best_overall['test_recall']:.4f}\")\n",
    "    \n",
    "#     print(f\"\\n2. Most Generalizable (least overfitting):\")\n",
    "#     print(f\"   Model: {least_overfit['experiment']}\")\n",
    "#     print(f\"   Overfit gap: {least_overfit['overfit_gap']:.4f}\")\n",
    "#     print(f\"   Test F1: {least_overfit['test_f1']:.4f}\")\n",
    "    \n",
    "#     print(f\"\\n3. Best for Minimizing False Negatives (high recall):\")\n",
    "#     print(f\"   Model: {best_recall['experiment']}\")\n",
    "#     print(f\"   Recall: {best_recall['test_recall']:.4f} (catches {best_recall['test_recall']*100:.1f}% of deforestation)\")\n",
    "    \n",
    "#     print(f\"\\n4. Best for Minimizing False Positives (high precision):\")\n",
    "#     print(f\"   Model: {best_precision['experiment']}\")\n",
    "#     print(f\"   Precision: {best_precision['test_precision']:.4f} ({best_precision['test_precision']*100:.1f}% of predictions are correct)\")\n",
    "    \n",
    "#     # General insights\n",
    "#     print(f\"\\n5. Key Insights:\")\n",
    "    \n",
    "#     # Input type\n",
    "#     best_input = df.groupby('input_type')['test_f1'].mean().idxmax()\n",
    "#     print(f\"   - Best input representation: {best_input}\")\n",
    "    \n",
    "#     # Regularization\n",
    "#     if df['overfit_gap'].mean() > 0.1:\n",
    "#         print(f\"   - Strong overfitting detected (avg gap: {df['overfit_gap'].mean():.3f})\")\n",
    "#         print(f\"     â†’ Consider: higher dropout, weight decay, or simpler models\")\n",
    "    \n",
    "#     # Dropout sweet spot\n",
    "#     if len(df['dropout'].unique()) > 1:\n",
    "#         dropout_perf = df.groupby('dropout')['test_f1'].mean()\n",
    "#         best_dropout = dropout_perf.idxmax()\n",
    "#         print(f\"   - Optimal dropout rate appears to be: {best_dropout}\")\n",
    "\n",
    "\n",
    "# def main():\n",
    "#     \"\"\"Main analysis function\"\"\"\n",
    "#     # Load results\n",
    "#     results, summary_file = load_experiment_results()\n",
    "    \n",
    "#     if not results:\n",
    "#         print(\"No experiment results found or all experiments failed!\")\n",
    "#         return\n",
    "    \n",
    "#     # Convert to DataFrame\n",
    "#     df = results_to_dataframe(results)\n",
    "    \n",
    "#     # Print summary table\n",
    "#     print_summary_table(df)\n",
    "    \n",
    "#     # Analyze by category\n",
    "#     analyze_by_category(df)\n",
    "    \n",
    "#     # Generate recommendations\n",
    "#     generate_recommendations(df)\n",
    "    \n",
    "#     # Create visualizations\n",
    "#     viz_path = root_path / \"experiments\" / f\"analysis_{summary_file.stem}.png\"\n",
    "#     plot_experiment_comparison(df, save_path=viz_path)\n",
    "    \n",
    "#     # Plot confusion matrices for top 3\n",
    "#     cm_path = root_path / \"experiments\" / f\"confusion_matrices_{summary_file.stem}.png\"\n",
    "#     plot_top_models_confusion(results, top_n=3, save_path=cm_path)\n",
    "    \n",
    "#     print(f\"\\n{'='*100}\")\n",
    "#     print(\"Analysis complete!\")\n",
    "#     print(f\"{'='*100}\")\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae73ed24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "burned_embedder",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
